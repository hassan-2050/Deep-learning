{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of Concrete Strength Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q_Qfg0wFSuY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynf5v1nUFSu5"
      },
      "source": [
        "###  Description:\n",
        "| Features Name | Data Type | Measurement | Description |\n",
        "| -- | -- | -- | -- |\n",
        "Cement (component 1) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Blast Furnace Slag (component 2) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Fly Ash (component 3) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Water (component 4) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Superplasticizer (component 5) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Coarse Aggregate (component 6) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Fine Aggregate (component 7) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Age | quantitative | Day (1~365) | Input Variable\n",
        "Concrete compressive strength | quantitative | MPa | Output Variable\n",
        "\n",
        "### WORKFLOW :\n",
        "- Load Data\n",
        "- Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
        "- Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "- Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "- Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
        "- Train the Model with Epochs (100) and validate it\n",
        "- If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
        "- Evaluation Step\n",
        "- Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtZiUtruFSu-"
      },
      "source": [
        "# Load Data:\n",
        "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/compresive_strength_concrete.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1Q9O9mlL0-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a47492-ae0f-4968-d244-723e304a249f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq-Eo905L1rO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "d=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/compresive_strength_concrete.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbgxsyKmMfsa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "66a5404e-5724-47c3-cd7c-9b704b6c8743"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
              "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
              "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
              "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
              "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
              "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
              "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
              "      <th>Age (day)</th>\n",
              "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>276.4</td>\n",
              "      <td>116.0</td>\n",
              "      <td>90.3</td>\n",
              "      <td>179.6</td>\n",
              "      <td>8.9</td>\n",
              "      <td>870.1</td>\n",
              "      <td>768.3</td>\n",
              "      <td>28</td>\n",
              "      <td>44.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026</th>\n",
              "      <td>322.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.6</td>\n",
              "      <td>196.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>817.9</td>\n",
              "      <td>813.4</td>\n",
              "      <td>28</td>\n",
              "      <td>31.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>148.5</td>\n",
              "      <td>139.4</td>\n",
              "      <td>108.6</td>\n",
              "      <td>192.7</td>\n",
              "      <td>6.1</td>\n",
              "      <td>892.4</td>\n",
              "      <td>780.0</td>\n",
              "      <td>28</td>\n",
              "      <td>23.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1028</th>\n",
              "      <td>159.1</td>\n",
              "      <td>186.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>175.6</td>\n",
              "      <td>11.3</td>\n",
              "      <td>989.6</td>\n",
              "      <td>788.9</td>\n",
              "      <td>28</td>\n",
              "      <td>32.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>260.9</td>\n",
              "      <td>100.5</td>\n",
              "      <td>78.3</td>\n",
              "      <td>200.6</td>\n",
              "      <td>8.6</td>\n",
              "      <td>864.5</td>\n",
              "      <td>761.5</td>\n",
              "      <td>28</td>\n",
              "      <td>32.40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1030 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Cement (component 1)(kg in a m^3 mixture)  ...  Concrete compressive strength(MPa, megapascals) \n",
              "0                                         540.0  ...                                             79.99\n",
              "1                                         540.0  ...                                             61.89\n",
              "2                                         332.5  ...                                             40.27\n",
              "3                                         332.5  ...                                             41.05\n",
              "4                                         198.6  ...                                             44.30\n",
              "...                                         ...  ...                                               ...\n",
              "1025                                      276.4  ...                                             44.28\n",
              "1026                                      322.2  ...                                             31.18\n",
              "1027                                      148.5  ...                                             23.70\n",
              "1028                                      159.1  ...                                             32.77\n",
              "1029                                      260.9  ...                                             32.40\n",
              "\n",
              "[1030 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTBoGneAMq-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1b1d0e-09eb-4f39-b140-a67ce9a3a96b"
      },
      "source": [
        "d.isnull().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cement (component 1)(kg in a m^3 mixture)                False\n",
              "Blast Furnace Slag (component 2)(kg in a m^3 mixture)    False\n",
              "Fly Ash (component 3)(kg in a m^3 mixture)               False\n",
              "Water  (component 4)(kg in a m^3 mixture)                False\n",
              "Superplasticizer (component 5)(kg in a m^3 mixture)      False\n",
              "Coarse Aggregate  (component 6)(kg in a m^3 mixture)     False\n",
              "Fine Aggregate (component 7)(kg in a m^3 mixture)        False\n",
              "Age (day)                                                False\n",
              "Concrete compressive strength(MPa, megapascals)          False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt7JoFlm2AHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7443ae77-f82f-436b-97c1-c285f0416f19"
      },
      "source": [
        "x=d.drop(columns=\"Concrete compressive strength(MPa, megapascals) \")\n",
        "y=d.loc[:,\"Concrete compressive strength(MPa, megapascals) \"].values\n",
        "y\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([79.99, 61.89, 40.27, ..., 23.7 , 32.77, 32.4 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjGHsumZ4JcW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V38ZRJQY2tZz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVV2ivSJHJEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857e390c-5915-4d15-9fab-d8323c06b586"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(309, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0STZ4yf122G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511cda1b-b381-4513-9c00-165a7d4cc63d"
      },
      "source": [
        "val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(145, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-F1GMkg2dxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecabf721-4def-426b-f8c9-aff058da147c"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(576, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeJhP_GbdGkm"
      },
      "source": [
        "#using relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijNH0Pws6EI9"
      },
      "source": [
        "from keras import models,layers\n",
        "model=models.Sequential()\n",
        "model.add(layers.Dense(10,activation=\"relu\",input_shape=(8,)))\n",
        "model.add(layers.Dense(8,activation=\"relu\"))\n",
        "model.add(layers.Dense(6,activation=\"relu\"))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjNHvgbM8LjJ"
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XM0DjIt-t7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eec1aac-d483-47a3-899b-6eeeea72bf16"
      },
      "source": [
        "h=model.fit(x_train,y_train,epochs=200,batch_size=20,validation_data=(val,y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "29/29 [==============================] - 1s 15ms/step - loss: 13581.4840 - mae: 108.5562 - val_loss: 1034.0013 - val_mae: 28.1267\n",
            "Epoch 2/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 703.1193 - mae: 21.5458 - val_loss: 285.4248 - val_mae: 13.1847\n",
            "Epoch 3/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 229.0404 - mae: 12.1444 - val_loss: 228.1517 - val_mae: 11.9213\n",
            "Epoch 4/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 183.8343 - mae: 11.0997 - val_loss: 192.2527 - val_mae: 10.9682\n",
            "Epoch 5/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 193.8728 - mae: 11.4125 - val_loss: 202.2316 - val_mae: 11.3355\n",
            "Epoch 6/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 170.2727 - mae: 10.5003 - val_loss: 188.1026 - val_mae: 10.9799\n",
            "Epoch 7/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 172.5412 - mae: 10.3823 - val_loss: 192.7960 - val_mae: 11.1101\n",
            "Epoch 8/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 142.1795 - mae: 9.4395 - val_loss: 149.4857 - val_mae: 9.7681\n",
            "Epoch 9/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 146.8947 - mae: 9.7815 - val_loss: 147.0470 - val_mae: 9.5479\n",
            "Epoch 10/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 130.9393 - mae: 8.9180 - val_loss: 138.7216 - val_mae: 9.3504\n",
            "Epoch 11/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 123.7948 - mae: 8.9799 - val_loss: 131.1988 - val_mae: 9.0668\n",
            "Epoch 12/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 121.4556 - mae: 8.7589 - val_loss: 125.1543 - val_mae: 8.8283\n",
            "Epoch 13/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 117.4178 - mae: 8.5051 - val_loss: 122.6740 - val_mae: 8.7417\n",
            "Epoch 14/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 112.3543 - mae: 8.4387 - val_loss: 129.2267 - val_mae: 8.9062\n",
            "Epoch 15/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 121.6627 - mae: 8.8611 - val_loss: 115.1142 - val_mae: 8.4859\n",
            "Epoch 16/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 126.8429 - mae: 8.9681 - val_loss: 111.5921 - val_mae: 8.3954\n",
            "Epoch 17/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 116.3368 - mae: 8.4905 - val_loss: 110.6850 - val_mae: 8.3261\n",
            "Epoch 18/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 109.9829 - mae: 8.4257 - val_loss: 111.6191 - val_mae: 8.6222\n",
            "Epoch 19/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 114.5568 - mae: 8.6525 - val_loss: 95.8753 - val_mae: 7.8606\n",
            "Epoch 20/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 109.2990 - mae: 8.1405 - val_loss: 94.6590 - val_mae: 7.7939\n",
            "Epoch 21/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 106.5598 - mae: 8.2531 - val_loss: 100.3059 - val_mae: 7.9818\n",
            "Epoch 22/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 110.9753 - mae: 8.2242 - val_loss: 96.1538 - val_mae: 7.8208\n",
            "Epoch 23/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 96.9282 - mae: 7.5375 - val_loss: 94.7144 - val_mae: 7.8182\n",
            "Epoch 24/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 103.7711 - mae: 8.0073 - val_loss: 118.7385 - val_mae: 8.5149\n",
            "Epoch 25/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 105.3736 - mae: 8.1713 - val_loss: 128.4765 - val_mae: 8.9142\n",
            "Epoch 26/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 110.6311 - mae: 8.2084 - val_loss: 90.0909 - val_mae: 7.6250\n",
            "Epoch 27/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 98.7323 - mae: 7.7847 - val_loss: 89.2472 - val_mae: 7.5825\n",
            "Epoch 28/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 102.4280 - mae: 7.8475 - val_loss: 96.1872 - val_mae: 7.7580\n",
            "Epoch 29/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 111.1550 - mae: 8.1646 - val_loss: 92.3171 - val_mae: 7.7198\n",
            "Epoch 30/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 93.5572 - mae: 7.4942 - val_loss: 107.5800 - val_mae: 8.5031\n",
            "Epoch 31/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 91.4970 - mae: 7.5127 - val_loss: 89.9673 - val_mae: 7.6423\n",
            "Epoch 32/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 103.8633 - mae: 7.9614 - val_loss: 96.7589 - val_mae: 7.7484\n",
            "Epoch 33/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 99.6074 - mae: 7.8712 - val_loss: 123.2638 - val_mae: 8.7553\n",
            "Epoch 34/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 99.7270 - mae: 7.9356 - val_loss: 93.5623 - val_mae: 7.8265\n",
            "Epoch 35/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 106.0695 - mae: 7.9866 - val_loss: 131.7082 - val_mae: 9.1020\n",
            "Epoch 36/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 92.1705 - mae: 7.4169 - val_loss: 94.6205 - val_mae: 7.6538\n",
            "Epoch 37/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 100.2951 - mae: 8.0900 - val_loss: 97.3455 - val_mae: 7.7221\n",
            "Epoch 38/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 91.4565 - mae: 7.4092 - val_loss: 117.6578 - val_mae: 8.5615\n",
            "Epoch 39/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 108.7729 - mae: 7.9884 - val_loss: 89.7660 - val_mae: 7.6853\n",
            "Epoch 40/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 85.3134 - mae: 6.9872 - val_loss: 103.5724 - val_mae: 7.9501\n",
            "Epoch 41/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 93.7727 - mae: 7.6316 - val_loss: 95.8707 - val_mae: 7.6057\n",
            "Epoch 42/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 93.8343 - mae: 7.5360 - val_loss: 116.4184 - val_mae: 8.4649\n",
            "Epoch 43/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 96.4421 - mae: 7.6369 - val_loss: 82.8136 - val_mae: 7.3854\n",
            "Epoch 44/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 91.4495 - mae: 7.4431 - val_loss: 83.1828 - val_mae: 7.3719\n",
            "Epoch 45/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 81.2908 - mae: 6.8894 - val_loss: 76.4322 - val_mae: 7.0317\n",
            "Epoch 46/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 92.2326 - mae: 7.2978 - val_loss: 118.4293 - val_mae: 8.6345\n",
            "Epoch 47/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 88.7874 - mae: 7.4025 - val_loss: 78.6955 - val_mae: 7.2265\n",
            "Epoch 48/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 92.5561 - mae: 7.4208 - val_loss: 76.4684 - val_mae: 7.0979\n",
            "Epoch 49/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 78.9775 - mae: 6.7338 - val_loss: 71.1347 - val_mae: 6.8353\n",
            "Epoch 50/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 92.1343 - mae: 7.3918 - val_loss: 96.2758 - val_mae: 7.6817\n",
            "Epoch 51/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 84.0479 - mae: 6.9635 - val_loss: 73.7532 - val_mae: 6.8905\n",
            "Epoch 52/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 74.6858 - mae: 6.5649 - val_loss: 84.7414 - val_mae: 7.2016\n",
            "Epoch 53/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 81.0539 - mae: 6.8656 - val_loss: 71.8129 - val_mae: 6.8129\n",
            "Epoch 54/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 80.8562 - mae: 6.8835 - val_loss: 72.6686 - val_mae: 6.8186\n",
            "Epoch 55/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 76.8276 - mae: 6.9000 - val_loss: 83.2463 - val_mae: 7.1136\n",
            "Epoch 56/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 72.8981 - mae: 6.5624 - val_loss: 68.4029 - val_mae: 6.6928\n",
            "Epoch 57/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 74.1730 - mae: 6.5524 - val_loss: 72.1630 - val_mae: 6.9036\n",
            "Epoch 58/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 77.6536 - mae: 6.8938 - val_loss: 66.9142 - val_mae: 6.6065\n",
            "Epoch 59/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 82.2055 - mae: 6.9492 - val_loss: 88.7118 - val_mae: 7.3707\n",
            "Epoch 60/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 81.6665 - mae: 6.9812 - val_loss: 67.5539 - val_mae: 6.6357\n",
            "Epoch 61/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 71.6096 - mae: 6.4786 - val_loss: 69.8278 - val_mae: 6.7534\n",
            "Epoch 62/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 79.5822 - mae: 6.9595 - val_loss: 100.9871 - val_mae: 8.3179\n",
            "Epoch 63/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 80.7596 - mae: 6.9911 - val_loss: 83.1489 - val_mae: 7.1254\n",
            "Epoch 64/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 63.9232 - mae: 6.0076 - val_loss: 77.9852 - val_mae: 7.1946\n",
            "Epoch 65/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 73.6797 - mae: 6.5513 - val_loss: 82.1431 - val_mae: 7.4574\n",
            "Epoch 66/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 79.7724 - mae: 6.8186 - val_loss: 62.8145 - val_mae: 6.3372\n",
            "Epoch 67/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 70.7310 - mae: 6.3248 - val_loss: 71.7199 - val_mae: 6.8800\n",
            "Epoch 68/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 70.7572 - mae: 6.5187 - val_loss: 65.1255 - val_mae: 6.4901\n",
            "Epoch 69/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 70.9785 - mae: 6.6322 - val_loss: 61.2520 - val_mae: 6.2090\n",
            "Epoch 70/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 77.6034 - mae: 6.8502 - val_loss: 64.0134 - val_mae: 6.4432\n",
            "Epoch 71/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 72.6292 - mae: 6.4866 - val_loss: 61.8130 - val_mae: 6.3375\n",
            "Epoch 72/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 72.6661 - mae: 6.5580 - val_loss: 62.2220 - val_mae: 6.3587\n",
            "Epoch 73/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 71.6761 - mae: 6.4816 - val_loss: 67.5973 - val_mae: 6.6768\n",
            "Epoch 74/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 68.4871 - mae: 6.3716 - val_loss: 61.8206 - val_mae: 6.2218\n",
            "Epoch 75/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 70.8437 - mae: 6.3393 - val_loss: 64.9593 - val_mae: 6.5239\n",
            "Epoch 76/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 63.6615 - mae: 6.1763 - val_loss: 59.9691 - val_mae: 6.1082\n",
            "Epoch 77/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 64.6069 - mae: 6.1995 - val_loss: 59.3257 - val_mae: 6.0849\n",
            "Epoch 78/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 66.2676 - mae: 6.2217 - val_loss: 76.6617 - val_mae: 6.7872\n",
            "Epoch 79/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 62.1791 - mae: 5.9253 - val_loss: 56.6123 - val_mae: 5.9873\n",
            "Epoch 80/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 65.1024 - mae: 6.1220 - val_loss: 56.8944 - val_mae: 5.8699\n",
            "Epoch 81/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 69.1431 - mae: 6.3508 - val_loss: 56.1824 - val_mae: 5.9183\n",
            "Epoch 82/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 61.9106 - mae: 5.9417 - val_loss: 87.1291 - val_mae: 7.2657\n",
            "Epoch 83/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 61.1336 - mae: 5.9122 - val_loss: 74.6812 - val_mae: 7.0011\n",
            "Epoch 84/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 66.2921 - mae: 6.3647 - val_loss: 63.3616 - val_mae: 6.4558\n",
            "Epoch 85/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 62.3511 - mae: 6.1239 - val_loss: 64.5706 - val_mae: 6.1731\n",
            "Epoch 86/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 59.6717 - mae: 6.0319 - val_loss: 56.6772 - val_mae: 6.0916\n",
            "Epoch 87/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 65.7553 - mae: 6.4250 - val_loss: 63.1745 - val_mae: 6.5278\n",
            "Epoch 88/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 59.4385 - mae: 5.8618 - val_loss: 65.7832 - val_mae: 6.2188\n",
            "Epoch 89/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 57.2557 - mae: 5.7944 - val_loss: 50.6552 - val_mae: 5.6901\n",
            "Epoch 90/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 65.6226 - mae: 6.2320 - val_loss: 50.6110 - val_mae: 5.7576\n",
            "Epoch 91/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 65.0457 - mae: 6.1357 - val_loss: 48.3305 - val_mae: 5.5147\n",
            "Epoch 92/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 60.2689 - mae: 6.0463 - val_loss: 49.7265 - val_mae: 5.6121\n",
            "Epoch 93/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 54.7294 - mae: 5.8793 - val_loss: 55.3740 - val_mae: 5.7719\n",
            "Epoch 94/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 54.1658 - mae: 5.5589 - val_loss: 78.7454 - val_mae: 7.3664\n",
            "Epoch 95/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 68.3395 - mae: 6.4117 - val_loss: 56.9501 - val_mae: 6.0729\n",
            "Epoch 96/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 53.5449 - mae: 5.6446 - val_loss: 54.0843 - val_mae: 5.6259\n",
            "Epoch 97/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 57.8643 - mae: 5.9215 - val_loss: 91.1011 - val_mae: 7.5313\n",
            "Epoch 98/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 65.1294 - mae: 6.0914 - val_loss: 48.2485 - val_mae: 5.5226\n",
            "Epoch 99/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 64.9906 - mae: 6.2464 - val_loss: 57.2754 - val_mae: 5.7741\n",
            "Epoch 100/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 59.0310 - mae: 5.8948 - val_loss: 46.1280 - val_mae: 5.3398\n",
            "Epoch 101/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 60.8894 - mae: 6.0269 - val_loss: 47.3688 - val_mae: 5.4360\n",
            "Epoch 102/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 52.2317 - mae: 5.4671 - val_loss: 44.6828 - val_mae: 5.2227\n",
            "Epoch 103/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 56.3797 - mae: 5.8010 - val_loss: 68.7245 - val_mae: 6.9386\n",
            "Epoch 104/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 56.9566 - mae: 5.8742 - val_loss: 63.8910 - val_mae: 6.5758\n",
            "Epoch 105/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 54.1152 - mae: 5.7271 - val_loss: 48.6686 - val_mae: 5.4781\n",
            "Epoch 106/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 51.0095 - mae: 5.4843 - val_loss: 54.9756 - val_mae: 6.0190\n",
            "Epoch 107/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 52.8886 - mae: 5.5565 - val_loss: 46.7243 - val_mae: 5.2399\n",
            "Epoch 108/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 45.9646 - mae: 5.2082 - val_loss: 112.8562 - val_mae: 9.0802\n",
            "Epoch 109/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 57.6708 - mae: 5.9574 - val_loss: 51.7514 - val_mae: 5.4835\n",
            "Epoch 110/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 48.4339 - mae: 5.2454 - val_loss: 48.5481 - val_mae: 5.3269\n",
            "Epoch 111/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 48.5813 - mae: 5.2676 - val_loss: 53.3120 - val_mae: 5.8987\n",
            "Epoch 112/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 53.5181 - mae: 5.6859 - val_loss: 46.3777 - val_mae: 5.3486\n",
            "Epoch 113/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 51.1162 - mae: 5.4537 - val_loss: 46.5422 - val_mae: 5.3105\n",
            "Epoch 114/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 58.3429 - mae: 5.8757 - val_loss: 44.4071 - val_mae: 5.1809\n",
            "Epoch 115/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 50.9644 - mae: 5.5306 - val_loss: 47.7608 - val_mae: 5.2596\n",
            "Epoch 116/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 54.1272 - mae: 5.6283 - val_loss: 44.8510 - val_mae: 5.1064\n",
            "Epoch 117/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 47.0334 - mae: 5.1058 - val_loss: 62.1711 - val_mae: 6.5230\n",
            "Epoch 118/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 56.7820 - mae: 5.9540 - val_loss: 44.5439 - val_mae: 5.1039\n",
            "Epoch 119/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 52.1434 - mae: 5.4494 - val_loss: 44.5494 - val_mae: 5.1976\n",
            "Epoch 120/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 52.8016 - mae: 5.6352 - val_loss: 56.8259 - val_mae: 5.7734\n",
            "Epoch 121/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 49.6915 - mae: 5.3381 - val_loss: 51.5135 - val_mae: 5.4676\n",
            "Epoch 122/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 48.8526 - mae: 5.3277 - val_loss: 59.3324 - val_mae: 6.3875\n",
            "Epoch 123/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 45.0868 - mae: 5.3021 - val_loss: 44.7923 - val_mae: 5.0625\n",
            "Epoch 124/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 49.7132 - mae: 5.4335 - val_loss: 47.5955 - val_mae: 5.2170\n",
            "Epoch 125/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 58.0985 - mae: 5.8425 - val_loss: 46.3249 - val_mae: 5.2484\n",
            "Epoch 126/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 57.1760 - mae: 5.7990 - val_loss: 84.6087 - val_mae: 7.6218\n",
            "Epoch 127/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 56.2280 - mae: 5.9039 - val_loss: 47.6812 - val_mae: 5.1961\n",
            "Epoch 128/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 55.2534 - mae: 5.5955 - val_loss: 43.9162 - val_mae: 4.9847\n",
            "Epoch 129/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 55.0644 - mae: 5.7201 - val_loss: 46.7289 - val_mae: 5.1749\n",
            "Epoch 130/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 55.5601 - mae: 5.8771 - val_loss: 46.4793 - val_mae: 5.3602\n",
            "Epoch 131/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 45.1820 - mae: 5.2381 - val_loss: 45.7571 - val_mae: 5.1585\n",
            "Epoch 132/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 49.4807 - mae: 5.2964 - val_loss: 59.0679 - val_mae: 6.3696\n",
            "Epoch 133/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 53.3648 - mae: 5.7399 - val_loss: 45.1510 - val_mae: 5.1219\n",
            "Epoch 134/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 51.7690 - mae: 5.6628 - val_loss: 65.7956 - val_mae: 6.4297\n",
            "Epoch 135/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 46.1306 - mae: 5.1461 - val_loss: 45.5063 - val_mae: 5.1504\n",
            "Epoch 136/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 45.2929 - mae: 5.0638 - val_loss: 45.4215 - val_mae: 5.2078\n",
            "Epoch 137/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 50.6909 - mae: 5.3392 - val_loss: 48.6648 - val_mae: 5.2839\n",
            "Epoch 138/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 50.1616 - mae: 5.5010 - val_loss: 48.0739 - val_mae: 5.2653\n",
            "Epoch 139/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 53.4167 - mae: 5.5743 - val_loss: 43.0232 - val_mae: 4.9750\n",
            "Epoch 140/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 44.3685 - mae: 5.0489 - val_loss: 44.7586 - val_mae: 5.0537\n",
            "Epoch 141/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 44.2014 - mae: 5.0133 - val_loss: 67.5102 - val_mae: 6.5082\n",
            "Epoch 142/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 54.5936 - mae: 5.6611 - val_loss: 58.6605 - val_mae: 5.9714\n",
            "Epoch 143/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 55.3354 - mae: 5.7318 - val_loss: 61.2333 - val_mae: 6.0795\n",
            "Epoch 144/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 46.3094 - mae: 5.2066 - val_loss: 47.5629 - val_mae: 5.1970\n",
            "Epoch 145/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 46.4376 - mae: 5.1532 - val_loss: 48.5524 - val_mae: 5.5061\n",
            "Epoch 146/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 53.4946 - mae: 5.8446 - val_loss: 43.1715 - val_mae: 4.9420\n",
            "Epoch 147/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 47.3315 - mae: 5.2624 - val_loss: 43.9184 - val_mae: 5.0774\n",
            "Epoch 148/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 48.6599 - mae: 5.4654 - val_loss: 53.5935 - val_mae: 5.9635\n",
            "Epoch 149/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 48.7359 - mae: 5.3164 - val_loss: 43.6861 - val_mae: 5.1000\n",
            "Epoch 150/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 49.0937 - mae: 5.3112 - val_loss: 42.9975 - val_mae: 4.9637\n",
            "Epoch 151/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 43.6699 - mae: 5.0300 - val_loss: 44.0493 - val_mae: 4.9853\n",
            "Epoch 152/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 48.8644 - mae: 5.3362 - val_loss: 44.6679 - val_mae: 5.1593\n",
            "Epoch 153/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 49.4057 - mae: 5.4243 - val_loss: 44.4781 - val_mae: 5.0085\n",
            "Epoch 154/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 47.1447 - mae: 5.2464 - val_loss: 48.4784 - val_mae: 5.5206\n",
            "Epoch 155/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 42.9084 - mae: 5.0280 - val_loss: 50.8079 - val_mae: 5.7412\n",
            "Epoch 156/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 49.5419 - mae: 5.4519 - val_loss: 49.2165 - val_mae: 5.3270\n",
            "Epoch 157/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 51.6067 - mae: 5.5539 - val_loss: 44.7723 - val_mae: 5.0463\n",
            "Epoch 158/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 46.4233 - mae: 5.1426 - val_loss: 44.9453 - val_mae: 5.0312\n",
            "Epoch 159/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 49.6702 - mae: 5.3278 - val_loss: 44.2829 - val_mae: 5.0102\n",
            "Epoch 160/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 47.1076 - mae: 5.3129 - val_loss: 48.9532 - val_mae: 5.5770\n",
            "Epoch 161/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 50.5457 - mae: 5.3859 - val_loss: 46.8309 - val_mae: 5.1941\n",
            "Epoch 162/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 49.7638 - mae: 5.4669 - val_loss: 44.5404 - val_mae: 5.1111\n",
            "Epoch 163/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 56.9690 - mae: 5.7812 - val_loss: 43.6102 - val_mae: 5.0685\n",
            "Epoch 164/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 45.1193 - mae: 5.1496 - val_loss: 52.9729 - val_mae: 5.8851\n",
            "Epoch 165/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 49.5371 - mae: 5.5199 - val_loss: 54.3252 - val_mae: 5.6489\n",
            "Epoch 166/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 46.5870 - mae: 5.2496 - val_loss: 45.2289 - val_mae: 5.2120\n",
            "Epoch 167/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 47.1457 - mae: 5.2443 - val_loss: 44.4303 - val_mae: 5.0968\n",
            "Epoch 168/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 48.1046 - mae: 5.2778 - val_loss: 43.6184 - val_mae: 5.0304\n",
            "Epoch 169/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 43.3281 - mae: 5.0323 - val_loss: 47.3757 - val_mae: 5.2670\n",
            "Epoch 170/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 44.7491 - mae: 5.1226 - val_loss: 53.1524 - val_mae: 5.5382\n",
            "Epoch 171/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 46.2318 - mae: 5.1976 - val_loss: 45.5443 - val_mae: 5.3033\n",
            "Epoch 172/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 54.3718 - mae: 5.9119 - val_loss: 43.9551 - val_mae: 5.0406\n",
            "Epoch 173/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 46.6034 - mae: 5.2439 - val_loss: 48.2717 - val_mae: 5.2612\n",
            "Epoch 174/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 49.9266 - mae: 5.4081 - val_loss: 46.6142 - val_mae: 5.4038\n",
            "Epoch 175/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 54.7674 - mae: 5.7158 - val_loss: 43.9926 - val_mae: 5.0472\n",
            "Epoch 176/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 48.2489 - mae: 5.2414 - val_loss: 43.3083 - val_mae: 5.0937\n",
            "Epoch 177/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 47.4944 - mae: 5.3135 - val_loss: 44.1528 - val_mae: 5.0733\n",
            "Epoch 178/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 45.0774 - mae: 5.2048 - val_loss: 44.4459 - val_mae: 5.0687\n",
            "Epoch 179/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 48.9404 - mae: 5.4254 - val_loss: 44.7434 - val_mae: 5.1198\n",
            "Epoch 180/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 47.6711 - mae: 5.3901 - val_loss: 46.1605 - val_mae: 5.2292\n",
            "Epoch 181/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 46.1737 - mae: 5.2290 - val_loss: 52.1481 - val_mae: 5.5190\n",
            "Epoch 182/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 46.3353 - mae: 5.1099 - val_loss: 46.7209 - val_mae: 5.2187\n",
            "Epoch 183/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 48.3878 - mae: 5.3526 - val_loss: 43.3425 - val_mae: 5.0734\n",
            "Epoch 184/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 46.7169 - mae: 5.1296 - val_loss: 45.4411 - val_mae: 5.1712\n",
            "Epoch 185/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 45.9190 - mae: 5.1229 - val_loss: 43.3639 - val_mae: 5.1013\n",
            "Epoch 186/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 46.6490 - mae: 5.2613 - val_loss: 43.1469 - val_mae: 5.0626\n",
            "Epoch 187/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 49.4275 - mae: 5.4398 - val_loss: 51.2669 - val_mae: 5.8381\n",
            "Epoch 188/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 47.4764 - mae: 5.1908 - val_loss: 58.8958 - val_mae: 5.9646\n",
            "Epoch 189/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 45.2888 - mae: 5.0401 - val_loss: 46.3143 - val_mae: 5.4067\n",
            "Epoch 190/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 43.3121 - mae: 5.1145 - val_loss: 43.2649 - val_mae: 5.1112\n",
            "Epoch 191/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 49.6927 - mae: 5.5052 - val_loss: 43.9291 - val_mae: 5.1797\n",
            "Epoch 192/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 44.1260 - mae: 5.2367 - val_loss: 47.2451 - val_mae: 5.4618\n",
            "Epoch 193/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 44.5338 - mae: 5.1258 - val_loss: 56.3076 - val_mae: 5.7670\n",
            "Epoch 194/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 42.8919 - mae: 5.0043 - val_loss: 60.7205 - val_mae: 6.0439\n",
            "Epoch 195/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 49.3485 - mae: 5.3257 - val_loss: 56.4574 - val_mae: 5.8096\n",
            "Epoch 196/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 51.8019 - mae: 5.5036 - val_loss: 45.9159 - val_mae: 5.1903\n",
            "Epoch 197/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 37.4340 - mae: 4.6626 - val_loss: 71.7419 - val_mae: 6.6805\n",
            "Epoch 198/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 45.4755 - mae: 5.1918 - val_loss: 62.7361 - val_mae: 6.5552\n",
            "Epoch 199/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 45.6383 - mae: 5.3183 - val_loss: 47.0916 - val_mae: 5.2767\n",
            "Epoch 200/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 50.5017 - mae: 5.4446 - val_loss: 57.7432 - val_mae: 5.8836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFvj-3Y7dRdP"
      },
      "source": [
        "#using tanh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1HfHeUeCJU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eaba2fe-bc19-49d4-edbe-1d96803e4d04"
      },
      "source": [
        "from keras import models,layers\n",
        "model1=models.Sequential()\n",
        "model1.add(layers.Dense(10,activation=\"tanh\",input_shape=(8,)))\n",
        "model1.add(layers.Dense(8,activation=\"tanh\"))\n",
        "model1.add(layers.Dense(6,activation=\"tanh\"))\n",
        "model1.add(layers.Dense(1))\n",
        "model1.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])\n",
        "h=model1.fit(x_train,y_train,epochs=200,batch_size=100,validation_data=(val,y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "6/6 [==============================] - 1s 40ms/step - loss: 1556.5323 - mae: 35.9662 - val_loss: 1715.7883 - val_mae: 37.6909\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1471.3170 - mae: 34.7474 - val_loss: 1693.1160 - val_mae: 37.4162\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1509.0992 - mae: 35.2691 - val_loss: 1673.2787 - val_mae: 37.1600\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1435.8589 - mae: 34.3201 - val_loss: 1659.6539 - val_mae: 36.9679\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1478.5564 - mae: 34.7712 - val_loss: 1647.1293 - val_mae: 36.7867\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1387.8407 - mae: 33.5728 - val_loss: 1634.6395 - val_mae: 36.6098\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1456.3083 - mae: 34.4336 - val_loss: 1622.3851 - val_mae: 36.4294\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1440.2836 - mae: 34.2441 - val_loss: 1612.4707 - val_mae: 36.2838\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1424.8377 - mae: 33.9475 - val_loss: 1603.9573 - val_mae: 36.1670\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1404.0837 - mae: 33.7628 - val_loss: 1596.2944 - val_mae: 36.0619\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1474.9535 - mae: 34.7011 - val_loss: 1590.2578 - val_mae: 35.9761\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1333.9049 - mae: 32.9205 - val_loss: 1583.9381 - val_mae: 35.8879\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1389.7668 - mae: 33.5463 - val_loss: 1578.7037 - val_mae: 35.8145\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1411.9137 - mae: 33.8665 - val_loss: 1573.9946 - val_mae: 35.7486\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1377.3055 - mae: 33.4224 - val_loss: 1569.5557 - val_mae: 35.6865\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1345.1720 - mae: 33.1211 - val_loss: 1564.9243 - val_mae: 35.6232\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1368.8894 - mae: 33.3900 - val_loss: 1560.8145 - val_mae: 35.5654\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1338.4244 - mae: 32.8844 - val_loss: 1556.9987 - val_mae: 35.5118\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1331.4109 - mae: 33.0314 - val_loss: 1553.2302 - val_mae: 35.4589\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1333.7805 - mae: 32.7879 - val_loss: 1549.5991 - val_mae: 35.4075\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1357.1104 - mae: 33.0910 - val_loss: 1546.0992 - val_mae: 35.3581\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1342.7255 - mae: 32.9229 - val_loss: 1542.5588 - val_mae: 35.3080\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1311.7165 - mae: 32.6660 - val_loss: 1538.8459 - val_mae: 35.2559\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1323.9586 - mae: 32.5815 - val_loss: 1535.2765 - val_mae: 35.2053\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1366.5892 - mae: 33.1471 - val_loss: 1531.7937 - val_mae: 35.1558\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1366.2972 - mae: 33.0244 - val_loss: 1528.2786 - val_mae: 35.1058\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1363.5131 - mae: 33.0182 - val_loss: 1524.8296 - val_mae: 35.0566\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1384.5893 - mae: 33.2919 - val_loss: 1521.4254 - val_mae: 35.0080\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1337.8917 - mae: 32.6303 - val_loss: 1518.0419 - val_mae: 34.9597\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1311.2547 - mae: 32.5476 - val_loss: 1514.6541 - val_mae: 34.9112\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1294.4422 - mae: 32.2217 - val_loss: 1511.3284 - val_mae: 34.8635\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1319.7461 - mae: 32.4514 - val_loss: 1508.0299 - val_mae: 34.8162\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1317.2153 - mae: 32.5325 - val_loss: 1504.7798 - val_mae: 34.7694\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1367.0761 - mae: 33.2991 - val_loss: 1501.5686 - val_mae: 34.7231\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1309.4163 - mae: 32.4228 - val_loss: 1498.3474 - val_mae: 34.6767\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1304.2343 - mae: 32.0941 - val_loss: 1495.1556 - val_mae: 34.6307\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1308.2839 - mae: 32.4089 - val_loss: 1491.9852 - val_mae: 34.5848\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1295.8513 - mae: 31.9873 - val_loss: 1488.8479 - val_mae: 34.5395\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1330.9227 - mae: 32.5101 - val_loss: 1485.7509 - val_mae: 34.4946\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1273.8725 - mae: 31.8718 - val_loss: 1482.6204 - val_mae: 34.4491\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1287.1206 - mae: 32.0596 - val_loss: 1479.5444 - val_mae: 34.4044\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1327.6741 - mae: 32.6999 - val_loss: 1476.5000 - val_mae: 34.3602\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1278.4888 - mae: 31.6116 - val_loss: 1473.4601 - val_mae: 34.3159\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1255.4791 - mae: 31.4756 - val_loss: 1470.4281 - val_mae: 34.2717\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1261.3054 - mae: 31.6084 - val_loss: 1467.4049 - val_mae: 34.2276\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1273.6464 - mae: 31.7972 - val_loss: 1464.4095 - val_mae: 34.1838\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1238.3556 - mae: 31.4525 - val_loss: 1461.4203 - val_mae: 34.1400\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1279.3565 - mae: 31.8495 - val_loss: 1458.4615 - val_mae: 34.0967\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1204.9168 - mae: 30.7590 - val_loss: 1455.4974 - val_mae: 34.0532\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1318.5506 - mae: 32.4176 - val_loss: 1452.5894 - val_mae: 34.0104\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1259.8922 - mae: 31.6101 - val_loss: 1449.6472 - val_mae: 33.9672\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1260.3195 - mae: 31.6179 - val_loss: 1446.7156 - val_mae: 33.9240\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1287.4033 - mae: 31.9263 - val_loss: 1443.8143 - val_mae: 33.8812\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1288.7567 - mae: 31.9244 - val_loss: 1440.9128 - val_mae: 33.8383\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1204.9937 - mae: 30.7264 - val_loss: 1437.9912 - val_mae: 33.7951\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1250.9410 - mae: 31.3575 - val_loss: 1435.1019 - val_mae: 33.7524\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1213.5240 - mae: 31.0259 - val_loss: 1432.2294 - val_mae: 33.7098\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1247.8647 - mae: 31.3010 - val_loss: 1429.3615 - val_mae: 33.6672\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1240.5260 - mae: 31.2606 - val_loss: 1426.5045 - val_mae: 33.6248\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1266.8258 - mae: 31.8715 - val_loss: 1423.6635 - val_mae: 33.5825\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1255.9824 - mae: 31.3984 - val_loss: 1420.8081 - val_mae: 33.5399\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1233.1654 - mae: 31.3931 - val_loss: 1417.9749 - val_mae: 33.4977\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1243.9952 - mae: 31.3910 - val_loss: 1415.1438 - val_mae: 33.4554\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1273.1906 - mae: 31.7710 - val_loss: 1412.3164 - val_mae: 33.4131\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1271.7520 - mae: 31.4735 - val_loss: 1409.4944 - val_mae: 33.3709\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1227.3071 - mae: 30.9002 - val_loss: 1406.6522 - val_mae: 33.3283\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1241.7182 - mae: 31.3431 - val_loss: 1403.8494 - val_mae: 33.2862\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1240.7021 - mae: 31.1231 - val_loss: 1401.0406 - val_mae: 33.2440\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1174.9870 - mae: 30.3712 - val_loss: 1398.2230 - val_mae: 33.2016\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1223.4368 - mae: 30.8673 - val_loss: 1395.4204 - val_mae: 33.1593\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1244.1523 - mae: 31.3376 - val_loss: 1392.6364 - val_mae: 33.1173\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1204.4169 - mae: 30.7951 - val_loss: 1389.8431 - val_mae: 33.0751\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1240.4903 - mae: 31.2136 - val_loss: 1387.0715 - val_mae: 33.0332\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1213.3325 - mae: 30.9095 - val_loss: 1384.2964 - val_mae: 32.9912\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1174.3540 - mae: 30.3840 - val_loss: 1381.5193 - val_mae: 32.9490\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1198.6543 - mae: 30.4517 - val_loss: 1378.7498 - val_mae: 32.9070\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1195.9626 - mae: 30.6036 - val_loss: 1375.9893 - val_mae: 32.8650\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1214.7055 - mae: 30.6659 - val_loss: 1373.2103 - val_mae: 32.8227\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1216.2186 - mae: 30.9152 - val_loss: 1370.4723 - val_mae: 32.7810\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1149.2122 - mae: 29.9516 - val_loss: 1367.6985 - val_mae: 32.7386\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1196.0269 - mae: 30.5171 - val_loss: 1364.9763 - val_mae: 32.6970\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1151.7664 - mae: 30.0064 - val_loss: 1362.2266 - val_mae: 32.6550\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1201.2441 - mae: 30.4756 - val_loss: 1359.4882 - val_mae: 32.6130\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1148.4760 - mae: 29.9703 - val_loss: 1356.7418 - val_mae: 32.5709\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1158.6885 - mae: 29.9522 - val_loss: 1354.0061 - val_mae: 32.5289\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1134.1010 - mae: 29.6431 - val_loss: 1351.2843 - val_mae: 32.4870\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1199.3746 - mae: 30.5387 - val_loss: 1348.5679 - val_mae: 32.4452\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1228.1117 - mae: 30.7916 - val_loss: 1345.8685 - val_mae: 32.4035\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1151.6323 - mae: 29.8452 - val_loss: 1343.1478 - val_mae: 32.3615\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1162.9004 - mae: 30.0573 - val_loss: 1340.4229 - val_mae: 32.3194\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1173.7561 - mae: 30.2663 - val_loss: 1337.7185 - val_mae: 32.2775\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1092.6633 - mae: 28.7165 - val_loss: 1334.9958 - val_mae: 32.2353\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1142.5996 - mae: 29.7653 - val_loss: 1332.3022 - val_mae: 32.1935\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1159.7584 - mae: 30.0807 - val_loss: 1329.6162 - val_mae: 32.1518\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1126.3434 - mae: 29.5404 - val_loss: 1326.9265 - val_mae: 32.1099\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1167.4144 - mae: 30.1446 - val_loss: 1324.2577 - val_mae: 32.0683\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1121.8970 - mae: 29.4778 - val_loss: 1321.5533 - val_mae: 32.0261\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1125.2589 - mae: 29.3799 - val_loss: 1318.8562 - val_mae: 31.9840\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1095.8012 - mae: 28.9909 - val_loss: 1316.1831 - val_mae: 31.9422\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1108.2020 - mae: 28.9602 - val_loss: 1313.4946 - val_mae: 31.9001\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1132.8603 - mae: 29.4099 - val_loss: 1310.8372 - val_mae: 31.8584\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1146.6220 - mae: 29.7951 - val_loss: 1308.1788 - val_mae: 31.8166\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1130.8051 - mae: 29.4801 - val_loss: 1305.5280 - val_mae: 31.7750\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1094.2545 - mae: 28.9581 - val_loss: 1302.8628 - val_mae: 31.7330\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1099.2570 - mae: 29.1272 - val_loss: 1300.2045 - val_mae: 31.6911\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1060.7982 - mae: 28.3455 - val_loss: 1297.5363 - val_mae: 31.6490\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1045.6051 - mae: 28.1296 - val_loss: 1294.8824 - val_mae: 31.6070\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1076.5894 - mae: 28.6471 - val_loss: 1292.2457 - val_mae: 31.5653\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1089.7935 - mae: 28.8867 - val_loss: 1289.6115 - val_mae: 31.5235\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1104.4671 - mae: 28.8436 - val_loss: 1286.9860 - val_mae: 31.4818\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1113.4382 - mae: 29.4002 - val_loss: 1284.3574 - val_mae: 31.4401\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1084.4741 - mae: 28.6905 - val_loss: 1281.7229 - val_mae: 31.3981\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1145.2091 - mae: 29.3848 - val_loss: 1279.0966 - val_mae: 31.3563\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1106.9923 - mae: 29.2186 - val_loss: 1276.4784 - val_mae: 31.3145\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1084.9329 - mae: 28.9106 - val_loss: 1273.8613 - val_mae: 31.2727\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1086.3158 - mae: 28.8357 - val_loss: 1271.2458 - val_mae: 31.2309\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1136.9416 - mae: 29.5897 - val_loss: 1268.6462 - val_mae: 31.1892\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1109.8139 - mae: 29.1164 - val_loss: 1266.0299 - val_mae: 31.1472\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1120.5707 - mae: 29.2887 - val_loss: 1263.4191 - val_mae: 31.1053\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1050.6865 - mae: 28.2180 - val_loss: 1260.8086 - val_mae: 31.0633\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1075.9094 - mae: 28.6093 - val_loss: 1258.2034 - val_mae: 31.0213\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1042.1652 - mae: 28.0948 - val_loss: 1255.5903 - val_mae: 30.9792\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1056.9339 - mae: 28.1511 - val_loss: 1253.0123 - val_mae: 30.9376\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1112.8634 - mae: 29.0425 - val_loss: 1250.4443 - val_mae: 30.8960\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1076.0131 - mae: 28.2575 - val_loss: 1247.8472 - val_mae: 30.8540\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1095.6019 - mae: 28.9447 - val_loss: 1245.2716 - val_mae: 30.8122\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1016.5719 - mae: 27.4489 - val_loss: 1242.6597 - val_mae: 30.7698\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1014.8107 - mae: 27.6195 - val_loss: 1240.0830 - val_mae: 30.7279\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1098.9498 - mae: 28.9395 - val_loss: 1237.5492 - val_mae: 30.6866\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1061.0021 - mae: 28.4457 - val_loss: 1234.9862 - val_mae: 30.6448\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1052.4420 - mae: 28.3551 - val_loss: 1232.4293 - val_mae: 30.6031\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1026.2866 - mae: 27.8728 - val_loss: 1229.8622 - val_mae: 30.5611\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1105.1292 - mae: 28.8150 - val_loss: 1227.3174 - val_mae: 30.5195\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1063.1423 - mae: 28.3986 - val_loss: 1224.7675 - val_mae: 30.4777\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1060.6580 - mae: 28.3642 - val_loss: 1222.2180 - val_mae: 30.4358\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1039.8840 - mae: 28.0693 - val_loss: 1219.6621 - val_mae: 30.3938\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1072.6980 - mae: 28.3181 - val_loss: 1217.1326 - val_mae: 30.3521\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1067.6211 - mae: 28.0112 - val_loss: 1214.5863 - val_mae: 30.3102\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1057.2935 - mae: 28.1333 - val_loss: 1212.0638 - val_mae: 30.2685\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1032.5969 - mae: 27.7825 - val_loss: 1209.5267 - val_mae: 30.2266\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1036.8632 - mae: 28.0873 - val_loss: 1207.0049 - val_mae: 30.1848\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1011.3184 - mae: 27.4749 - val_loss: 1204.4646 - val_mae: 30.1427\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 995.7042 - mae: 27.1928 - val_loss: 1201.9205 - val_mae: 30.1005\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 993.1901 - mae: 27.0392 - val_loss: 1199.3945 - val_mae: 30.0585\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1031.1972 - mae: 27.7387 - val_loss: 1196.8949 - val_mae: 30.0169\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1012.9159 - mae: 27.3429 - val_loss: 1194.3842 - val_mae: 29.9751\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1005.3800 - mae: 27.3287 - val_loss: 1191.8744 - val_mae: 29.9332\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1012.5047 - mae: 27.3474 - val_loss: 1189.3719 - val_mae: 29.8913\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1025.1058 - mae: 27.6098 - val_loss: 1186.8723 - val_mae: 29.8495\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1019.7355 - mae: 27.3360 - val_loss: 1184.3938 - val_mae: 29.8079\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1012.2710 - mae: 27.3344 - val_loss: 1181.9010 - val_mae: 29.7661\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1006.5036 - mae: 27.3481 - val_loss: 1179.4258 - val_mae: 29.7245\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1034.1344 - mae: 27.7829 - val_loss: 1176.9357 - val_mae: 29.6826\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1027.1863 - mae: 27.5204 - val_loss: 1174.4468 - val_mae: 29.6406\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 999.0585 - mae: 27.0400 - val_loss: 1171.9757 - val_mae: 29.5989\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 981.4453 - mae: 26.9588 - val_loss: 1169.4994 - val_mae: 29.5571\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 959.9402 - mae: 26.5803 - val_loss: 1167.0084 - val_mae: 29.5149\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 986.9948 - mae: 27.0286 - val_loss: 1164.5446 - val_mae: 29.4736\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 963.2177 - mae: 26.6524 - val_loss: 1162.0731 - val_mae: 29.4322\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1026.1387 - mae: 27.6233 - val_loss: 1159.6438 - val_mae: 29.3914\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 967.9220 - mae: 26.7852 - val_loss: 1157.1544 - val_mae: 29.3496\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 960.7883 - mae: 26.6716 - val_loss: 1154.7074 - val_mae: 29.3085\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 949.5049 - mae: 26.5404 - val_loss: 1152.2628 - val_mae: 29.2673\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 971.7890 - mae: 26.9295 - val_loss: 1149.8396 - val_mae: 29.2265\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 985.7195 - mae: 27.0783 - val_loss: 1147.4021 - val_mae: 29.1853\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1007.0533 - mae: 27.1556 - val_loss: 1144.9716 - val_mae: 29.1442\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 972.3740 - mae: 26.8893 - val_loss: 1142.5366 - val_mae: 29.1030\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1011.1175 - mae: 27.2733 - val_loss: 1140.1040 - val_mae: 29.0617\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 978.0823 - mae: 26.9316 - val_loss: 1137.6641 - val_mae: 29.0203\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 946.5088 - mae: 26.2678 - val_loss: 1135.2183 - val_mae: 28.9787\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 944.7044 - mae: 26.3338 - val_loss: 1132.7905 - val_mae: 28.9373\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 970.8127 - mae: 26.5601 - val_loss: 1130.3800 - val_mae: 28.8962\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 980.5070 - mae: 26.9380 - val_loss: 1127.9739 - val_mae: 28.8551\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 953.0638 - mae: 26.5025 - val_loss: 1125.5675 - val_mae: 28.8140\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 956.5112 - mae: 26.4559 - val_loss: 1123.1492 - val_mae: 28.7731\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1010.4644 - mae: 27.2019 - val_loss: 1120.7698 - val_mae: 28.7329\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 972.3002 - mae: 26.4635 - val_loss: 1118.3618 - val_mae: 28.6921\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 976.4519 - mae: 26.8682 - val_loss: 1115.9856 - val_mae: 28.6517\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1009.1522 - mae: 27.1076 - val_loss: 1113.5952 - val_mae: 28.6111\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 907.4325 - mae: 25.6837 - val_loss: 1111.1759 - val_mae: 28.5700\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 924.7606 - mae: 25.8879 - val_loss: 1108.7767 - val_mae: 28.5291\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 956.2464 - mae: 26.4328 - val_loss: 1106.4058 - val_mae: 28.4886\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 953.5689 - mae: 26.3589 - val_loss: 1104.0308 - val_mae: 28.4480\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 962.5368 - mae: 26.5528 - val_loss: 1101.6807 - val_mae: 28.4078\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 970.3297 - mae: 26.5639 - val_loss: 1099.3132 - val_mae: 28.3672\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 997.9211 - mae: 27.0971 - val_loss: 1096.9454 - val_mae: 28.3266\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 937.4368 - mae: 26.3082 - val_loss: 1094.5739 - val_mae: 28.2858\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 928.6898 - mae: 26.0595 - val_loss: 1092.1935 - val_mae: 28.2448\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 947.3081 - mae: 25.9669 - val_loss: 1089.8250 - val_mae: 28.2040\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 957.2756 - mae: 26.3403 - val_loss: 1087.4756 - val_mae: 28.1634\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 939.6372 - mae: 26.1791 - val_loss: 1085.1331 - val_mae: 28.1229\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 943.8683 - mae: 26.1808 - val_loss: 1082.8004 - val_mae: 28.0825\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 911.5548 - mae: 25.6949 - val_loss: 1080.4391 - val_mae: 28.0416\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 926.7636 - mae: 25.8235 - val_loss: 1078.0927 - val_mae: 28.0008\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 970.6901 - mae: 26.6003 - val_loss: 1075.7728 - val_mae: 27.9604\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 924.5998 - mae: 26.0535 - val_loss: 1073.4504 - val_mae: 27.9201\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 934.1730 - mae: 25.7818 - val_loss: 1071.1064 - val_mae: 27.8798\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 867.4706 - mae: 24.7958 - val_loss: 1068.7568 - val_mae: 27.8393\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 888.9638 - mae: 25.1870 - val_loss: 1066.4326 - val_mae: 27.7992\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 927.1188 - mae: 25.6845 - val_loss: 1064.1233 - val_mae: 27.7593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLHtXgskDL5H"
      },
      "source": [
        "# Adding droupout \n",
        "## no increse in accuracy as neural network isnt deep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEM23nijX1FA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a7795b-b805-410c-afa8-206618ca1464"
      },
      "source": [
        "from keras import models,layers\n",
        "modela=models.Sequential()\n",
        "modela.add(layers.Dense(10,activation=\"relu\",input_shape=(8,)))\n",
        "modela.add(layers.Dropout(0.3))\n",
        "modela.add(layers.Dense(8,activation=\"relu\"))\n",
        "modela.add(layers.Dropout(0.3))\n",
        "modela.add(layers.Dense(6,activation=\"relu\"))\n",
        "modela.add(layers.Dense(1))\n",
        "modela.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])\n",
        "h=modela.fit(x_train,y_train,epochs=100,batch_size=100,validation_data=(val,y_val))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 36ms/step - loss: 16943.9392 - mae: 102.3341 - val_loss: 3861.5000 - val_mae: 57.2237\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10163.2923 - mae: 77.3347 - val_loss: 1374.4288 - val_mae: 30.2655\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6069.5013 - mae: 58.2685 - val_loss: 505.6862 - val_mae: 17.7882\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4528.0322 - mae: 47.4081 - val_loss: 297.6504 - val_mae: 13.8276\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3440.6338 - mae: 41.9857 - val_loss: 283.6527 - val_mae: 13.5998\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2404.2996 - mae: 36.2189 - val_loss: 348.9576 - val_mae: 14.8596\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2420.0383 - mae: 35.6758 - val_loss: 403.4131 - val_mae: 16.1175\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1856.6729 - mae: 31.2216 - val_loss: 427.7672 - val_mae: 16.6287\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1751.0169 - mae: 31.8327 - val_loss: 463.4583 - val_mae: 17.3770\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1193.9121 - mae: 26.1869 - val_loss: 506.0822 - val_mae: 18.1686\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1126.3322 - mae: 25.7683 - val_loss: 537.6616 - val_mae: 18.7790\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1224.4722 - mae: 25.7194 - val_loss: 556.1454 - val_mae: 19.1221\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1008.4532 - mae: 23.9310 - val_loss: 596.7266 - val_mae: 19.9103\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 994.4137 - mae: 22.7514 - val_loss: 612.9053 - val_mae: 20.2214\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 889.5357 - mae: 22.2468 - val_loss: 613.5563 - val_mae: 20.2190\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 919.1057 - mae: 22.1656 - val_loss: 600.0646 - val_mae: 19.9394\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 880.3236 - mae: 22.5824 - val_loss: 596.7960 - val_mae: 19.8651\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 663.3260 - mae: 20.2237 - val_loss: 579.2732 - val_mae: 19.5078\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 570.8791 - mae: 18.6367 - val_loss: 556.0135 - val_mae: 19.0384\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 708.7386 - mae: 20.5639 - val_loss: 555.0136 - val_mae: 19.0162\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 723.3390 - mae: 20.0524 - val_loss: 550.7719 - val_mae: 18.9338\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 666.7748 - mae: 19.2287 - val_loss: 564.6370 - val_mae: 19.2049\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 534.4997 - mae: 18.1304 - val_loss: 534.2466 - val_mae: 18.5983\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 573.8511 - mae: 18.4422 - val_loss: 502.0786 - val_mae: 17.9552\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 588.9329 - mae: 18.6254 - val_loss: 558.9562 - val_mae: 19.0991\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 563.5060 - mae: 17.9208 - val_loss: 513.8864 - val_mae: 18.2055\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 522.0642 - mae: 17.3920 - val_loss: 512.3404 - val_mae: 18.1889\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 470.2587 - mae: 16.8952 - val_loss: 528.8852 - val_mae: 18.5011\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 538.2613 - mae: 18.1599 - val_loss: 510.5085 - val_mae: 18.1291\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 529.7642 - mae: 17.3860 - val_loss: 529.7939 - val_mae: 18.5092\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 548.3310 - mae: 17.5410 - val_loss: 524.2393 - val_mae: 18.3953\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 470.6601 - mae: 16.6862 - val_loss: 489.2132 - val_mae: 17.6728\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 482.2400 - mae: 17.4468 - val_loss: 482.9254 - val_mae: 17.5266\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 429.1600 - mae: 16.2263 - val_loss: 492.4009 - val_mae: 17.7245\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 443.3618 - mae: 15.9716 - val_loss: 493.9026 - val_mae: 17.7542\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 466.1926 - mae: 16.8262 - val_loss: 471.3989 - val_mae: 17.2942\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 450.2067 - mae: 16.8330 - val_loss: 477.6170 - val_mae: 17.4228\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 394.6389 - mae: 16.0373 - val_loss: 527.2216 - val_mae: 18.4350\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 436.3013 - mae: 16.2201 - val_loss: 505.1049 - val_mae: 17.9852\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 468.2510 - mae: 16.2163 - val_loss: 499.9666 - val_mae: 17.8841\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 430.0654 - mae: 15.9384 - val_loss: 500.1345 - val_mae: 17.8768\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 380.9368 - mae: 15.5449 - val_loss: 508.8551 - val_mae: 18.0504\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 405.9567 - mae: 15.8834 - val_loss: 497.8048 - val_mae: 17.8241\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 396.3518 - mae: 15.4587 - val_loss: 504.5070 - val_mae: 17.9594\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 478.9234 - mae: 17.5364 - val_loss: 523.2169 - val_mae: 18.3448\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 370.7543 - mae: 15.2826 - val_loss: 501.8151 - val_mae: 17.8948\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 426.5975 - mae: 16.2868 - val_loss: 502.8386 - val_mae: 17.9224\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 396.8077 - mae: 15.5423 - val_loss: 523.3508 - val_mae: 18.3421\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 384.9648 - mae: 15.0094 - val_loss: 499.5562 - val_mae: 17.8577\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 401.6971 - mae: 15.2676 - val_loss: 522.5684 - val_mae: 18.3363\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 394.5519 - mae: 15.1526 - val_loss: 523.9367 - val_mae: 18.3625\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 339.7453 - mae: 14.7328 - val_loss: 496.5205 - val_mae: 17.7929\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 332.6670 - mae: 14.3974 - val_loss: 526.5930 - val_mae: 18.4266\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 343.8219 - mae: 14.6033 - val_loss: 494.6699 - val_mae: 17.7774\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 373.8266 - mae: 14.8946 - val_loss: 500.2137 - val_mae: 17.8755\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 352.6233 - mae: 14.9171 - val_loss: 507.9339 - val_mae: 18.0393\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 348.2994 - mae: 14.6636 - val_loss: 494.7160 - val_mae: 17.7906\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 357.8602 - mae: 14.8212 - val_loss: 450.0142 - val_mae: 16.8589\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 320.9890 - mae: 14.1671 - val_loss: 504.8649 - val_mae: 18.0001\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 362.7882 - mae: 14.8379 - val_loss: 511.2243 - val_mae: 18.1359\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 305.2437 - mae: 13.8222 - val_loss: 493.1812 - val_mae: 17.7242\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 334.8036 - mae: 14.3706 - val_loss: 499.5742 - val_mae: 17.8950\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 329.2445 - mae: 13.8406 - val_loss: 495.0383 - val_mae: 17.7901\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 382.0795 - mae: 14.9296 - val_loss: 488.3956 - val_mae: 17.6214\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 363.4550 - mae: 15.2719 - val_loss: 505.6446 - val_mae: 17.9884\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 349.7322 - mae: 14.7691 - val_loss: 494.1479 - val_mae: 17.7369\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 330.1217 - mae: 14.2206 - val_loss: 514.4314 - val_mae: 18.1620\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 337.4188 - mae: 14.2845 - val_loss: 518.8148 - val_mae: 18.2102\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 333.3523 - mae: 13.9545 - val_loss: 523.9446 - val_mae: 18.3349\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 312.9888 - mae: 13.9929 - val_loss: 523.3524 - val_mae: 18.2977\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 341.8804 - mae: 14.3704 - val_loss: 520.4003 - val_mae: 18.2580\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 279.1815 - mae: 13.1752 - val_loss: 513.6627 - val_mae: 18.1414\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 308.5891 - mae: 13.7171 - val_loss: 515.9116 - val_mae: 18.1656\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 308.0264 - mae: 13.7773 - val_loss: 527.1362 - val_mae: 18.3634\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 330.8742 - mae: 13.9259 - val_loss: 526.4700 - val_mae: 18.3723\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 288.5843 - mae: 13.1793 - val_loss: 523.8611 - val_mae: 18.3096\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 311.0327 - mae: 13.6797 - val_loss: 513.4947 - val_mae: 18.1104\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 321.1917 - mae: 14.0157 - val_loss: 513.4813 - val_mae: 18.1350\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 318.5713 - mae: 13.9792 - val_loss: 520.7253 - val_mae: 18.2684\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 280.7042 - mae: 12.8181 - val_loss: 519.8342 - val_mae: 18.2434\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 329.0127 - mae: 13.9304 - val_loss: 547.3929 - val_mae: 18.7822\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 294.9163 - mae: 13.5199 - val_loss: 549.0903 - val_mae: 18.7900\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 280.4827 - mae: 13.1658 - val_loss: 518.3391 - val_mae: 18.2314\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 289.2296 - mae: 13.2631 - val_loss: 514.5638 - val_mae: 18.1276\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 301.4816 - mae: 13.6086 - val_loss: 500.9667 - val_mae: 17.8936\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 291.7086 - mae: 13.1378 - val_loss: 512.2714 - val_mae: 18.0926\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 306.5937 - mae: 13.6100 - val_loss: 538.8397 - val_mae: 18.6021\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 373.5023 - mae: 14.8241 - val_loss: 539.4410 - val_mae: 18.6080\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 259.2917 - mae: 12.6376 - val_loss: 517.4061 - val_mae: 18.1673\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 298.0726 - mae: 13.2471 - val_loss: 526.3027 - val_mae: 18.3394\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 314.4138 - mae: 13.6045 - val_loss: 504.7695 - val_mae: 17.9177\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 300.0859 - mae: 13.5481 - val_loss: 496.7443 - val_mae: 17.7645\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 271.4607 - mae: 12.7727 - val_loss: 517.9116 - val_mae: 18.1867\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 284.3447 - mae: 13.4895 - val_loss: 512.5419 - val_mae: 18.0681\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 287.0440 - mae: 13.1643 - val_loss: 528.2021 - val_mae: 18.4054\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 263.7958 - mae: 13.0415 - val_loss: 513.1271 - val_mae: 18.1174\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 307.6201 - mae: 13.3842 - val_loss: 509.1321 - val_mae: 18.0334\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 272.1003 - mae: 12.7010 - val_loss: 479.3400 - val_mae: 17.5054\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 308.2623 - mae: 13.5962 - val_loss: 499.1786 - val_mae: 17.8619\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 297.9501 - mae: 13.2359 - val_loss: 526.3110 - val_mae: 18.4301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN49w1rqij6U"
      },
      "source": [
        "add regulizeer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZUrqdcZZoqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0338ee0-597d-4ec3-f922-af6ee3d33da9"
      },
      "source": [
        "from keras import models,layers,regularizers\n",
        "modelb=models.Sequential()\n",
        "modelb.add(layers.Dense(10,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001),input_shape=(8,)))\n",
        "modelb.add(layers.Dense(8,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001)))\n",
        "modelb.add(layers.Dense(6,activation=\"relu\",kernel_regularizer=regularizers.l2(0.001)))\n",
        "modelb.add(layers.Dense(1))\n",
        "modelb.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])\n",
        "h=modelb.fit(x_train,y_train,epochs=100,batch_size=100,validation_data=(val,y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 41ms/step - loss: 4909.4052 - mae: 64.1961 - val_loss: 1150.4358 - val_mae: 28.5242\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 934.8234 - mae: 26.2408 - val_loss: 775.7297 - val_mae: 23.5841\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 665.8323 - mae: 21.0150 - val_loss: 684.5131 - val_mae: 22.2142\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 613.6123 - mae: 20.2641 - val_loss: 599.8669 - val_mae: 20.6625\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 541.7862 - mae: 18.8743 - val_loss: 524.9260 - val_mae: 19.5163\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 469.1461 - mae: 17.7466 - val_loss: 473.5517 - val_mae: 18.6404\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 434.1686 - mae: 16.9626 - val_loss: 444.1683 - val_mae: 17.5953\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 403.6869 - mae: 16.2209 - val_loss: 388.4348 - val_mae: 16.7438\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 347.0169 - mae: 15.2148 - val_loss: 374.7881 - val_mae: 16.0346\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 319.2821 - mae: 14.5632 - val_loss: 328.3928 - val_mae: 15.4436\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 285.9648 - mae: 13.9082 - val_loss: 307.9839 - val_mae: 14.6498\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 288.9284 - mae: 13.9702 - val_loss: 282.8358 - val_mae: 14.1133\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 248.5705 - mae: 12.8863 - val_loss: 270.2943 - val_mae: 13.5442\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 226.4223 - mae: 12.3281 - val_loss: 268.2302 - val_mae: 13.3385\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 218.5250 - mae: 11.8384 - val_loss: 230.9257 - val_mae: 13.0220\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 213.5666 - mae: 11.7904 - val_loss: 214.7793 - val_mae: 12.5673\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 203.9326 - mae: 11.5295 - val_loss: 201.6731 - val_mae: 12.1818\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 185.8386 - mae: 11.0539 - val_loss: 191.7266 - val_mae: 11.8711\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 167.0891 - mae: 10.4984 - val_loss: 211.7993 - val_mae: 11.8186\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 173.0463 - mae: 10.5830 - val_loss: 207.1016 - val_mae: 11.5909\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 165.8627 - mae: 10.2442 - val_loss: 160.0916 - val_mae: 10.6796\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 151.5636 - mae: 9.9679 - val_loss: 222.5306 - val_mae: 11.8183\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 159.5208 - mae: 10.2428 - val_loss: 145.7428 - val_mae: 10.1751\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 139.5901 - mae: 9.5577 - val_loss: 140.9744 - val_mae: 10.0086\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 148.7402 - mae: 9.7710 - val_loss: 135.2632 - val_mae: 9.7962\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 131.2687 - mae: 9.2775 - val_loss: 147.7975 - val_mae: 9.8118\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 149.3457 - mae: 9.6511 - val_loss: 125.7336 - val_mae: 9.4199\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 117.4124 - mae: 8.5597 - val_loss: 135.0191 - val_mae: 9.7467\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 127.1745 - mae: 9.1357 - val_loss: 139.2308 - val_mae: 9.4578\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 117.8067 - mae: 8.7105 - val_loss: 130.6873 - val_mae: 9.2117\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 123.4309 - mae: 9.0577 - val_loss: 124.2288 - val_mae: 9.2958\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 128.4820 - mae: 9.0538 - val_loss: 113.1793 - val_mae: 8.8648\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 108.7283 - mae: 8.3942 - val_loss: 138.9371 - val_mae: 9.4226\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 127.9929 - mae: 9.0535 - val_loss: 116.0150 - val_mae: 8.7173\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 110.4639 - mae: 8.3130 - val_loss: 112.8102 - val_mae: 8.5913\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 117.7196 - mae: 8.7288 - val_loss: 104.6339 - val_mae: 8.3011\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 109.0658 - mae: 8.2156 - val_loss: 156.7658 - val_mae: 9.9737\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 130.9211 - mae: 8.9068 - val_loss: 100.4259 - val_mae: 8.2027\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 101.1458 - mae: 7.9069 - val_loss: 102.6468 - val_mae: 8.1703\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 106.0492 - mae: 8.1602 - val_loss: 99.5722 - val_mae: 8.0436\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.2717 - mae: 7.8697 - val_loss: 100.3914 - val_mae: 8.2437\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 104.0282 - mae: 7.9757 - val_loss: 112.8836 - val_mae: 8.5234\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 114.8600 - mae: 8.5533 - val_loss: 96.3650 - val_mae: 7.8884\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.1462 - mae: 7.6583 - val_loss: 94.5978 - val_mae: 7.9466\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 101.9928 - mae: 7.9883 - val_loss: 116.1697 - val_mae: 8.9507\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 103.0881 - mae: 8.0197 - val_loss: 97.0030 - val_mae: 7.8934\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 97.2652 - mae: 7.7584 - val_loss: 113.2934 - val_mae: 8.5005\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 100.9844 - mae: 7.8938 - val_loss: 91.6308 - val_mae: 7.7309\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.5168 - mae: 7.3467 - val_loss: 111.2672 - val_mae: 8.4237\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 110.8762 - mae: 8.3976 - val_loss: 107.7511 - val_mae: 8.2840\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.3220 - mae: 7.8877 - val_loss: 120.3320 - val_mae: 8.7480\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 107.3971 - mae: 8.4600 - val_loss: 93.1376 - val_mae: 7.9139\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 96.5830 - mae: 7.6750 - val_loss: 96.5486 - val_mae: 8.0953\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 106.7509 - mae: 8.1376 - val_loss: 92.2394 - val_mae: 7.6830\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 87.6073 - mae: 7.3207 - val_loss: 88.4175 - val_mae: 7.5907\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.2987 - mae: 7.0300 - val_loss: 128.5536 - val_mae: 9.0465\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 111.4071 - mae: 8.3771 - val_loss: 94.9336 - val_mae: 7.7633\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 89.7633 - mae: 7.4754 - val_loss: 100.6286 - val_mae: 7.9537\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 91.2409 - mae: 7.3656 - val_loss: 87.3795 - val_mae: 7.6084\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.3916 - mae: 6.9965 - val_loss: 90.4536 - val_mae: 7.8278\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 102.7512 - mae: 7.9712 - val_loss: 87.7042 - val_mae: 7.4634\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 88.0084 - mae: 7.2815 - val_loss: 124.5856 - val_mae: 8.8806\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 99.7516 - mae: 7.9341 - val_loss: 97.1771 - val_mae: 8.1375\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 93.1471 - mae: 7.5064 - val_loss: 85.2315 - val_mae: 7.4753\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 89.3331 - mae: 7.5066 - val_loss: 95.7809 - val_mae: 7.7402\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 103.6089 - mae: 7.9305 - val_loss: 84.3989 - val_mae: 7.3426\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 76.0715 - mae: 6.7327 - val_loss: 105.1646 - val_mae: 8.0857\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 88.4796 - mae: 7.4426 - val_loss: 99.8808 - val_mae: 7.8684\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 101.7169 - mae: 7.9775 - val_loss: 83.3404 - val_mae: 7.2795\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 85.8792 - mae: 7.2224 - val_loss: 95.8218 - val_mae: 7.7236\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 92.5840 - mae: 7.4331 - val_loss: 85.5658 - val_mae: 7.3306\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.8053 - mae: 7.0325 - val_loss: 99.4105 - val_mae: 7.8484\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 101.1215 - mae: 7.8395 - val_loss: 84.1525 - val_mae: 7.2771\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 79.7940 - mae: 6.8623 - val_loss: 82.5838 - val_mae: 7.4263\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 82.0549 - mae: 7.0392 - val_loss: 93.4977 - val_mae: 7.9718\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 106.9409 - mae: 8.2372 - val_loss: 81.3366 - val_mae: 7.2706\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 75.5769 - mae: 6.7507 - val_loss: 80.6918 - val_mae: 7.1950\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 79.9292 - mae: 6.8907 - val_loss: 93.6666 - val_mae: 7.6321\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 95.3825 - mae: 7.6526 - val_loss: 81.2518 - val_mae: 7.3549\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 84.5891 - mae: 7.0756 - val_loss: 80.1451 - val_mae: 7.2564\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 84.1693 - mae: 7.1555 - val_loss: 119.8863 - val_mae: 8.7706\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 93.8485 - mae: 7.7123 - val_loss: 80.1430 - val_mae: 7.1032\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 73.0801 - mae: 6.6884 - val_loss: 80.1483 - val_mae: 7.3168\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 96.1627 - mae: 7.6744 - val_loss: 79.6646 - val_mae: 7.0936\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.1838 - mae: 6.9149 - val_loss: 78.4233 - val_mae: 7.1707\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.1934 - mae: 7.0214 - val_loss: 102.7285 - val_mae: 8.0386\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.6230 - mae: 7.3077 - val_loss: 80.5347 - val_mae: 7.1166\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.8632 - mae: 7.1539 - val_loss: 106.4060 - val_mae: 8.2200\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 94.2318 - mae: 7.5796 - val_loss: 82.4762 - val_mae: 7.4590\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 81.5957 - mae: 7.0470 - val_loss: 85.3374 - val_mae: 7.5866\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 76.7170 - mae: 6.7681 - val_loss: 78.1680 - val_mae: 7.1646\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 88.9783 - mae: 7.4661 - val_loss: 79.2164 - val_mae: 7.2752\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 80.0312 - mae: 6.9145 - val_loss: 80.8413 - val_mae: 7.3610\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 70.7129 - mae: 6.4910 - val_loss: 77.9607 - val_mae: 7.1832\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 102.4312 - mae: 8.0559 - val_loss: 80.0934 - val_mae: 7.2973\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 78.7140 - mae: 6.8449 - val_loss: 76.2280 - val_mae: 6.9708\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 70.0444 - mae: 6.4662 - val_loss: 110.4101 - val_mae: 8.4407\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 77.1607 - mae: 6.7797 - val_loss: 80.2197 - val_mae: 7.0939\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 99.7763 - mae: 7.9449 - val_loss: 81.9840 - val_mae: 7.1487\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 82.1946 - mae: 7.0427 - val_loss: 81.5359 - val_mae: 7.3961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMPljHbaigh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e56c93-c01b-4bbc-a5f7-718e8d833b37"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 1ms/step - loss: 68.0345 - mae: 6.3498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[68.03450012207031, 6.349773406982422]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn_Ir_Dbdpcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f086e7d-ee1b-4e5b-a5ab-e8dec789dbbe"
      },
      "source": [
        "model1.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 1ms/step - loss: 1038.5326 - mae: 27.4086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1038.5325927734375, 27.408639907836914]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8jwmklxrxI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70cc8ac2-9cf0-4d13-d7cb-f3b29a375178"
      },
      "source": [
        "modela.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 1ms/step - loss: 502.8381 - mae: 18.2750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[502.83807373046875, 18.27504539489746]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA2xzJDQsBhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5437881-4aaa-49ce-9ebe-188e4252d028"
      },
      "source": [
        "modelb.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 80.1720 - mae: 7.0515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[80.17204284667969, 7.051506519317627]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE5gbidQfA_6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}