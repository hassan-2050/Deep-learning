{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Credit Card Fraud Detection assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzK8GWNdlQsF"
      },
      "source": [
        "# Credit Card Fraud Detection::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P0hqA1-lQsJ"
      },
      "source": [
        "Download dataset from this link:\n",
        "\n",
        "https://www.kaggle.com/mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E0Tm8Jmx8sX",
        "outputId": "7865a84e-c63b-434c-a158-6f7a714edc22"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmpXdYUBlQsL"
      },
      "source": [
        "# Description about dataset::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVepUvzelQsM"
      },
      "source": [
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
        "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
        "\n",
        "\n",
        "### Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luC6LYBdlQsO"
      },
      "source": [
        "# WORKFLOW :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ-LCfb5lQsP"
      },
      "source": [
        "1.Load Data\n",
        "\n",
        "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "\n",
        "3.Standardized the Input Variables. \n",
        "\n",
        "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "\n",
        "5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "\n",
        "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
        "\n",
        "7.Train the Model with Epochs (100).\n",
        "\n",
        "8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "\n",
        "9.Prediction should be > 92%\n",
        "10.Evaluation Step\n",
        "11Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJVazEYhlQsQ"
      },
      "source": [
        "# Task::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCRMf5uhlQsR"
      },
      "source": [
        "## Identify fraudulent credit card transactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL6FbuiIlQsS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfjuFQp8lQsS"
      },
      "source": [
        "d=pd.read_csv(\"/content/drive/MyDrive/data_sets/creditcard.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "y3IqV4jHlQsg",
        "outputId": "ba50db1a-e266-4968-fdbe-c524c7950fa0"
      },
      "source": [
        "d.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO_n-i5FlQsh",
        "outputId": "dfa50b3a-7e2d-4c4c-c9b0-6901abc0c7f1"
      },
      "source": [
        "d.isnull().sum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.sum of          Time     V1     V2     V3     V4  ...    V26    V27    V28  Amount  Class\n",
              "0       False  False  False  False  False  ...  False  False  False   False  False\n",
              "1       False  False  False  False  False  ...  False  False  False   False  False\n",
              "2       False  False  False  False  False  ...  False  False  False   False  False\n",
              "3       False  False  False  False  False  ...  False  False  False   False  False\n",
              "4       False  False  False  False  False  ...  False  False  False   False  False\n",
              "...       ...    ...    ...    ...    ...  ...    ...    ...    ...     ...    ...\n",
              "284802  False  False  False  False  False  ...  False  False  False   False  False\n",
              "284803  False  False  False  False  False  ...  False  False  False   False  False\n",
              "284804  False  False  False  False  False  ...  False  False  False   False  False\n",
              "284805  False  False  False  False  False  ...  False  False  False   False  False\n",
              "284806  False  False  False  False  False  ...  False  False  False   False  False\n",
              "\n",
              "[284807 rows x 31 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBfghCS4lQsh",
        "outputId": "cdad38a4-eed2-4753-b117-647e09e06604"
      },
      "source": [
        "d.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMXRDYgylQsi",
        "outputId": "1b6e5697-1132-47fa-96a3-b1693bbb61fa"
      },
      "source": [
        "d[\"Class\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8NUUN7eMXXv"
      },
      "source": [
        "as data is very unbalanced so we do bit processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_Ad4jhllQsj"
      },
      "source": [
        "non_fraud=d[d[\"Class\"]==0]\n",
        "fraud=d[d[\"Class\"]==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIZ2fWFglQsj",
        "outputId": "ec689e5a-5bdf-4581-f765-bc46ab0a50b3"
      },
      "source": [
        "fraud.shape,non_fraud.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((492, 31), (284315, 31))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBNuCrgbNR8R"
      },
      "source": [
        "make fraud and non fraud equal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRf92Z3elQsl"
      },
      "source": [
        "non_fraud=non_fraud.sample(fraud.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw0E9inklQsl",
        "outputId": "5603f647-a266-414c-f6a0-084e29f42420"
      },
      "source": [
        "non_fraud.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(492, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmfCf-BIlQsm"
      },
      "source": [
        "data=fraud.append(non_fraud,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLUHUaq7lQsn",
        "outputId": "dc7e520f-84ca-4e05-c370-79e7ba56b513"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(984, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIyV68NvlQsn",
        "outputId": "d434d92d-5ab3-4ace-dcf4-6a955037b10a"
      },
      "source": [
        "data[\"Class\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    492\n",
              "0    492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDNGYKA9lQso"
      },
      "source": [
        "x=data.drop(columns=\"Class\")\n",
        "y=data.Class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLFlbmaplQso",
        "outputId": "ff9ca2d8-50b5-40d0-9876-bfab426c69dd"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "979    0\n",
              "980    0\n",
              "981    0\n",
              "982    0\n",
              "983    0\n",
              "Name: Class, Length: 984, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX2N9VcSWWRf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbJDCKXJYW9T",
        "outputId": "c8f14250-c5a4-4c84-e9ac-77652e847ba1"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(688, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GTpbuUrZA8i",
        "outputId": "9fe6cddc-d17d-47b2-f3d4-999b22180f7e"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(296, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lC926NhcfBM"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "x_train,val,y_train,y_val=train_test_split(x_train,y_train,train_size=0.35,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8IkBrBjHLnJ"
      },
      "source": [
        "data scaled due to time column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALkYbzhCiACi"
      },
      "source": [
        "scaler=StandardScaler()\n",
        "x_train=scaler.fit_transform(x_train)\n",
        "x_test=scaler.transform(x_test)\n",
        "val=scaler.transform(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hRfbYcaigwx"
      },
      "source": [
        "y_train=y_train.to_numpy()\n",
        "y_test=y_test.to_numpy()\n",
        "y_val=y_val.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4giDIDJMkh7u",
        "outputId": "38246ae2-553e-449e-9f16-98e9d8ad4870"
      },
      "source": [
        "x_train.shape,x_test.shape,val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((240, 30), (296, 30), (448, 30))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQyweZWal758"
      },
      "source": [
        "from keras import models,layers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZUrqdcZZoqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebee7eea-edd5-49ea-baef-a6ce24371285"
      },
      "source": [
        "from keras import models,layers\n",
        "model=models.Sequential()\n",
        "model.add(layers.Dense(10,activation=\"relu\",input_shape=(30,)))\n",
        "model.add(layers.Dense(8,activation=\"relu\"))\n",
        "model.add(layers.Dense(6,activation=\"relu\"))\n",
        "model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
        "model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.fit(x_train,y_train,epochs=100,batch_size=128,validation_data=(val,y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 404ms/step - loss: 0.6752 - accuracy: 0.5295 - val_loss: 0.6776 - val_accuracy: 0.4978\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6681 - accuracy: 0.5413 - val_loss: 0.6694 - val_accuracy: 0.5670\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6568 - accuracy: 0.6135 - val_loss: 0.6619 - val_accuracy: 0.6049\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6511 - accuracy: 0.6141 - val_loss: 0.6549 - val_accuracy: 0.6272\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6441 - accuracy: 0.6389 - val_loss: 0.6486 - val_accuracy: 0.6496\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6366 - accuracy: 0.6740 - val_loss: 0.6422 - val_accuracy: 0.6719\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6305 - accuracy: 0.6821 - val_loss: 0.6361 - val_accuracy: 0.6830\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6222 - accuracy: 0.7059 - val_loss: 0.6304 - val_accuracy: 0.6920\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.6201 - accuracy: 0.7090 - val_loss: 0.6246 - val_accuracy: 0.7143\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6107 - accuracy: 0.7304 - val_loss: 0.6192 - val_accuracy: 0.7254\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6025 - accuracy: 0.7415 - val_loss: 0.6138 - val_accuracy: 0.7522\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6021 - accuracy: 0.7420 - val_loss: 0.6083 - val_accuracy: 0.7589\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5887 - accuracy: 0.7710 - val_loss: 0.6030 - val_accuracy: 0.7679\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5919 - accuracy: 0.7424 - val_loss: 0.5975 - val_accuracy: 0.7746\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5857 - accuracy: 0.7741 - val_loss: 0.5918 - val_accuracy: 0.7768\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5765 - accuracy: 0.7773 - val_loss: 0.5860 - val_accuracy: 0.7857\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5701 - accuracy: 0.7906 - val_loss: 0.5803 - val_accuracy: 0.7924\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5644 - accuracy: 0.8094 - val_loss: 0.5749 - val_accuracy: 0.8013\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.5600 - accuracy: 0.8174 - val_loss: 0.5695 - val_accuracy: 0.8192\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5553 - accuracy: 0.8312 - val_loss: 0.5641 - val_accuracy: 0.8214\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5555 - accuracy: 0.8208 - val_loss: 0.5584 - val_accuracy: 0.8281\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5461 - accuracy: 0.8286 - val_loss: 0.5527 - val_accuracy: 0.8304\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5377 - accuracy: 0.8340 - val_loss: 0.5470 - val_accuracy: 0.8371\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5323 - accuracy: 0.8292 - val_loss: 0.5414 - val_accuracy: 0.8460\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5234 - accuracy: 0.8398 - val_loss: 0.5360 - val_accuracy: 0.8460\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5244 - accuracy: 0.8401 - val_loss: 0.5304 - val_accuracy: 0.8504\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5120 - accuracy: 0.8665 - val_loss: 0.5248 - val_accuracy: 0.8527\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5192 - accuracy: 0.8592 - val_loss: 0.5192 - val_accuracy: 0.8571\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5076 - accuracy: 0.8856 - val_loss: 0.5136 - val_accuracy: 0.8616\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.4981 - accuracy: 0.8752 - val_loss: 0.5081 - val_accuracy: 0.8638\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5022 - accuracy: 0.8727 - val_loss: 0.5027 - val_accuracy: 0.8661\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4877 - accuracy: 0.8858 - val_loss: 0.4975 - val_accuracy: 0.8683\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4831 - accuracy: 0.8832 - val_loss: 0.4923 - val_accuracy: 0.8728\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4839 - accuracy: 0.8859 - val_loss: 0.4868 - val_accuracy: 0.8772\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.4736 - accuracy: 0.8833 - val_loss: 0.4815 - val_accuracy: 0.8772\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4756 - accuracy: 0.8781 - val_loss: 0.4765 - val_accuracy: 0.8795\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.4629 - accuracy: 0.8887 - val_loss: 0.4716 - val_accuracy: 0.8817\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4543 - accuracy: 0.8889 - val_loss: 0.4667 - val_accuracy: 0.8795\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.4429 - accuracy: 0.8941 - val_loss: 0.4619 - val_accuracy: 0.8839\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4309 - accuracy: 0.9045 - val_loss: 0.4573 - val_accuracy: 0.8884\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4393 - accuracy: 0.9075 - val_loss: 0.4523 - val_accuracy: 0.8884\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4369 - accuracy: 0.9024 - val_loss: 0.4472 - val_accuracy: 0.8884\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4307 - accuracy: 0.9076 - val_loss: 0.4422 - val_accuracy: 0.8884\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4234 - accuracy: 0.9102 - val_loss: 0.4373 - val_accuracy: 0.8884\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.4225 - accuracy: 0.9104 - val_loss: 0.4322 - val_accuracy: 0.8884\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4060 - accuracy: 0.9156 - val_loss: 0.4271 - val_accuracy: 0.8884\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4131 - accuracy: 0.9130 - val_loss: 0.4221 - val_accuracy: 0.8884\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4147 - accuracy: 0.9104 - val_loss: 0.4170 - val_accuracy: 0.8906\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3996 - accuracy: 0.9128 - val_loss: 0.4123 - val_accuracy: 0.8906\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3906 - accuracy: 0.9130 - val_loss: 0.4071 - val_accuracy: 0.8973\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.3860 - accuracy: 0.9210 - val_loss: 0.4020 - val_accuracy: 0.8973\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3857 - accuracy: 0.9158 - val_loss: 0.3967 - val_accuracy: 0.8996\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3830 - accuracy: 0.9158 - val_loss: 0.3916 - val_accuracy: 0.9040\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3676 - accuracy: 0.9184 - val_loss: 0.3869 - val_accuracy: 0.9062\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3674 - accuracy: 0.9212 - val_loss: 0.3819 - val_accuracy: 0.9062\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.3649 - accuracy: 0.9212 - val_loss: 0.3771 - val_accuracy: 0.9062\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3534 - accuracy: 0.9238 - val_loss: 0.3725 - val_accuracy: 0.9062\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3596 - accuracy: 0.9214 - val_loss: 0.3680 - val_accuracy: 0.9085\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3534 - accuracy: 0.9214 - val_loss: 0.3635 - val_accuracy: 0.9107\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3548 - accuracy: 0.9266 - val_loss: 0.3589 - val_accuracy: 0.9129\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3496 - accuracy: 0.9266 - val_loss: 0.3545 - val_accuracy: 0.9129\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3432 - accuracy: 0.9240 - val_loss: 0.3500 - val_accuracy: 0.9152\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3258 - accuracy: 0.9318 - val_loss: 0.3456 - val_accuracy: 0.9152\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3214 - accuracy: 0.9372 - val_loss: 0.3409 - val_accuracy: 0.9152\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3285 - accuracy: 0.9295 - val_loss: 0.3360 - val_accuracy: 0.9129\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.3190 - accuracy: 0.9347 - val_loss: 0.3313 - val_accuracy: 0.9152\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.3136 - accuracy: 0.9321 - val_loss: 0.3268 - val_accuracy: 0.9196\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2980 - accuracy: 0.9399 - val_loss: 0.3224 - val_accuracy: 0.9196\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.3035 - accuracy: 0.9347 - val_loss: 0.3182 - val_accuracy: 0.9196\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3057 - accuracy: 0.9241 - val_loss: 0.3138 - val_accuracy: 0.9219\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3064 - accuracy: 0.9269 - val_loss: 0.3097 - val_accuracy: 0.9219\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2981 - accuracy: 0.9293 - val_loss: 0.3059 - val_accuracy: 0.9196\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2986 - accuracy: 0.9295 - val_loss: 0.3019 - val_accuracy: 0.9174\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2875 - accuracy: 0.9321 - val_loss: 0.2980 - val_accuracy: 0.9174\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2896 - accuracy: 0.9297 - val_loss: 0.2943 - val_accuracy: 0.9196\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2803 - accuracy: 0.9349 - val_loss: 0.2907 - val_accuracy: 0.9219\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2804 - accuracy: 0.9375 - val_loss: 0.2872 - val_accuracy: 0.9219\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2608 - accuracy: 0.9401 - val_loss: 0.2839 - val_accuracy: 0.9241\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2712 - accuracy: 0.9375 - val_loss: 0.2805 - val_accuracy: 0.9241\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2608 - accuracy: 0.9375 - val_loss: 0.2771 - val_accuracy: 0.9241\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2519 - accuracy: 0.9401 - val_loss: 0.2742 - val_accuracy: 0.9263\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2561 - accuracy: 0.9375 - val_loss: 0.2709 - val_accuracy: 0.9286\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2523 - accuracy: 0.9427 - val_loss: 0.2682 - val_accuracy: 0.9286\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2387 - accuracy: 0.9535 - val_loss: 0.2656 - val_accuracy: 0.9263\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2497 - accuracy: 0.9483 - val_loss: 0.2628 - val_accuracy: 0.9263\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2409 - accuracy: 0.9429 - val_loss: 0.2598 - val_accuracy: 0.9263\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2377 - accuracy: 0.9431 - val_loss: 0.2572 - val_accuracy: 0.9263\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2386 - accuracy: 0.9486 - val_loss: 0.2544 - val_accuracy: 0.9263\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2204 - accuracy: 0.9536 - val_loss: 0.2521 - val_accuracy: 0.9308\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2470 - accuracy: 0.9460 - val_loss: 0.2496 - val_accuracy: 0.9263\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2187 - accuracy: 0.9590 - val_loss: 0.2474 - val_accuracy: 0.9263\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2321 - accuracy: 0.9512 - val_loss: 0.2451 - val_accuracy: 0.9263\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2183 - accuracy: 0.9590 - val_loss: 0.2433 - val_accuracy: 0.9263\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2194 - accuracy: 0.9564 - val_loss: 0.2413 - val_accuracy: 0.9241\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2149 - accuracy: 0.9538 - val_loss: 0.2389 - val_accuracy: 0.9263\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2170 - accuracy: 0.9538 - val_loss: 0.2365 - val_accuracy: 0.9263\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2049 - accuracy: 0.9590 - val_loss: 0.2351 - val_accuracy: 0.9241\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2120 - accuracy: 0.9512 - val_loss: 0.2328 - val_accuracy: 0.9241\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1863 - accuracy: 0.9668 - val_loss: 0.2315 - val_accuracy: 0.9263\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2092 - accuracy: 0.9564 - val_loss: 0.2294 - val_accuracy: 0.9263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efd84d26810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3rTfHNgCJp3"
      },
      "source": [
        "#bst model 96% accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5ngkipUrnhO",
        "outputId": "9047b935-5786-449f-da2f-c3c451b96ef3"
      },
      "source": [
        "from keras import models,layers\n",
        "model1=models.Sequential()\n",
        "model1.add(layers.Dense(10,activation=\"tanh\",input_shape=(30,)))\n",
        "model1.add(layers.Dense(8,activation=\"tanh\"))\n",
        "model1.add(layers.Dense(6,activation=\"tanh\"))\n",
        "model1.add(layers.Dense(1,activation=\"sigmoid\"))\n",
        "model1.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "model1.fit(x_train,y_train,epochs=100,batch_size=128,validation_data=(val,y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 182ms/step - loss: 0.6204 - accuracy: 0.6745 - val_loss: 0.5628 - val_accuracy: 0.7946\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5679 - accuracy: 0.8014 - val_loss: 0.5341 - val_accuracy: 0.8237\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.5431 - accuracy: 0.8071 - val_loss: 0.5117 - val_accuracy: 0.8281\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5198 - accuracy: 0.8158 - val_loss: 0.4927 - val_accuracy: 0.8460\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.5015 - accuracy: 0.8318 - val_loss: 0.4763 - val_accuracy: 0.8504\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4854 - accuracy: 0.8455 - val_loss: 0.4617 - val_accuracy: 0.8549\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4636 - accuracy: 0.8613 - val_loss: 0.4483 - val_accuracy: 0.8616\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4515 - accuracy: 0.8587 - val_loss: 0.4361 - val_accuracy: 0.8638\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4427 - accuracy: 0.8642 - val_loss: 0.4248 - val_accuracy: 0.8705\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4246 - accuracy: 0.8694 - val_loss: 0.4144 - val_accuracy: 0.8728\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.4139 - accuracy: 0.8750 - val_loss: 0.4048 - val_accuracy: 0.8750\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.4115 - accuracy: 0.8750 - val_loss: 0.3955 - val_accuracy: 0.8750\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3991 - accuracy: 0.8830 - val_loss: 0.3868 - val_accuracy: 0.8750\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3861 - accuracy: 0.8858 - val_loss: 0.3785 - val_accuracy: 0.8772\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3854 - accuracy: 0.8833 - val_loss: 0.3706 - val_accuracy: 0.8795\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3729 - accuracy: 0.8885 - val_loss: 0.3632 - val_accuracy: 0.8839\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3676 - accuracy: 0.8913 - val_loss: 0.3562 - val_accuracy: 0.8884\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3615 - accuracy: 0.8887 - val_loss: 0.3495 - val_accuracy: 0.8884\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3516 - accuracy: 0.8965 - val_loss: 0.3431 - val_accuracy: 0.8929\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.3330 - accuracy: 0.9017 - val_loss: 0.3370 - val_accuracy: 0.8929\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3427 - accuracy: 0.8861 - val_loss: 0.3310 - val_accuracy: 0.8929\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3439 - accuracy: 0.8835 - val_loss: 0.3252 - val_accuracy: 0.8929\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3252 - accuracy: 0.8939 - val_loss: 0.3199 - val_accuracy: 0.8929\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3340 - accuracy: 0.8863 - val_loss: 0.3145 - val_accuracy: 0.8951\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3259 - accuracy: 0.8915 - val_loss: 0.3095 - val_accuracy: 0.8973\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3103 - accuracy: 0.8993 - val_loss: 0.3046 - val_accuracy: 0.8973\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3116 - accuracy: 0.8915 - val_loss: 0.2999 - val_accuracy: 0.8996\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3005 - accuracy: 0.8967 - val_loss: 0.2953 - val_accuracy: 0.9040\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2994 - accuracy: 0.9021 - val_loss: 0.2909 - val_accuracy: 0.9040\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2982 - accuracy: 0.8995 - val_loss: 0.2866 - val_accuracy: 0.9040\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2995 - accuracy: 0.8943 - val_loss: 0.2825 - val_accuracy: 0.9085\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2934 - accuracy: 0.8969 - val_loss: 0.2785 - val_accuracy: 0.9085\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2848 - accuracy: 0.8995 - val_loss: 0.2745 - val_accuracy: 0.9107\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2775 - accuracy: 0.9021 - val_loss: 0.2707 - val_accuracy: 0.9129\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2743 - accuracy: 0.9047 - val_loss: 0.2670 - val_accuracy: 0.9129\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2762 - accuracy: 0.8995 - val_loss: 0.2633 - val_accuracy: 0.9129\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2727 - accuracy: 0.9076 - val_loss: 0.2597 - val_accuracy: 0.9152\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2767 - accuracy: 0.9026 - val_loss: 0.2562 - val_accuracy: 0.9174\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2550 - accuracy: 0.9182 - val_loss: 0.2529 - val_accuracy: 0.9196\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2493 - accuracy: 0.9156 - val_loss: 0.2498 - val_accuracy: 0.9196\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2483 - accuracy: 0.9210 - val_loss: 0.2466 - val_accuracy: 0.9219\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2456 - accuracy: 0.9184 - val_loss: 0.2435 - val_accuracy: 0.9219\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2479 - accuracy: 0.9210 - val_loss: 0.2404 - val_accuracy: 0.9241\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2389 - accuracy: 0.9184 - val_loss: 0.2373 - val_accuracy: 0.9219\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2470 - accuracy: 0.9160 - val_loss: 0.2343 - val_accuracy: 0.9241\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2442 - accuracy: 0.9160 - val_loss: 0.2314 - val_accuracy: 0.9241\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2417 - accuracy: 0.9212 - val_loss: 0.2285 - val_accuracy: 0.9241\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2349 - accuracy: 0.9212 - val_loss: 0.2258 - val_accuracy: 0.9241\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2341 - accuracy: 0.9186 - val_loss: 0.2232 - val_accuracy: 0.9263\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2384 - accuracy: 0.9134 - val_loss: 0.2206 - val_accuracy: 0.9286\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2254 - accuracy: 0.9212 - val_loss: 0.2180 - val_accuracy: 0.9286\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2299 - accuracy: 0.9212 - val_loss: 0.2156 - val_accuracy: 0.9286\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2196 - accuracy: 0.9212 - val_loss: 0.2132 - val_accuracy: 0.9286\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2188 - accuracy: 0.9186 - val_loss: 0.2108 - val_accuracy: 0.9263\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2018 - accuracy: 0.9316 - val_loss: 0.2086 - val_accuracy: 0.9308\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2050 - accuracy: 0.9290 - val_loss: 0.2066 - val_accuracy: 0.9308\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2123 - accuracy: 0.9160 - val_loss: 0.2045 - val_accuracy: 0.9353\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2093 - accuracy: 0.9238 - val_loss: 0.2024 - val_accuracy: 0.9353\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2034 - accuracy: 0.9238 - val_loss: 0.2005 - val_accuracy: 0.9375\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2027 - accuracy: 0.9240 - val_loss: 0.1986 - val_accuracy: 0.9353\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1953 - accuracy: 0.9240 - val_loss: 0.1967 - val_accuracy: 0.9353\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2044 - accuracy: 0.9241 - val_loss: 0.1949 - val_accuracy: 0.9353\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2050 - accuracy: 0.9293 - val_loss: 0.1932 - val_accuracy: 0.9353\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1926 - accuracy: 0.9319 - val_loss: 0.1916 - val_accuracy: 0.9353\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1848 - accuracy: 0.9373 - val_loss: 0.1900 - val_accuracy: 0.9397\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1917 - accuracy: 0.9347 - val_loss: 0.1884 - val_accuracy: 0.9397\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1844 - accuracy: 0.9347 - val_loss: 0.1870 - val_accuracy: 0.9397\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1940 - accuracy: 0.9321 - val_loss: 0.1856 - val_accuracy: 0.9397\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1929 - accuracy: 0.9267 - val_loss: 0.1842 - val_accuracy: 0.9375\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1783 - accuracy: 0.9373 - val_loss: 0.1830 - val_accuracy: 0.9375\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1860 - accuracy: 0.9349 - val_loss: 0.1817 - val_accuracy: 0.9375\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1744 - accuracy: 0.9375 - val_loss: 0.1806 - val_accuracy: 0.9375\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1901 - accuracy: 0.9323 - val_loss: 0.1794 - val_accuracy: 0.9375\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1611 - accuracy: 0.9479 - val_loss: 0.1785 - val_accuracy: 0.9397\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1767 - accuracy: 0.9403 - val_loss: 0.1775 - val_accuracy: 0.9420\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1652 - accuracy: 0.9453 - val_loss: 0.1766 - val_accuracy: 0.9442\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1842 - accuracy: 0.9323 - val_loss: 0.1757 - val_accuracy: 0.9442\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1740 - accuracy: 0.9349 - val_loss: 0.1747 - val_accuracy: 0.9442\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1747 - accuracy: 0.9377 - val_loss: 0.1738 - val_accuracy: 0.9420\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1713 - accuracy: 0.9429 - val_loss: 0.1730 - val_accuracy: 0.9442\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1554 - accuracy: 0.9509 - val_loss: 0.1722 - val_accuracy: 0.9442\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1551 - accuracy: 0.9481 - val_loss: 0.1717 - val_accuracy: 0.9442\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1770 - accuracy: 0.9378 - val_loss: 0.1709 - val_accuracy: 0.9442\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1536 - accuracy: 0.9483 - val_loss: 0.1703 - val_accuracy: 0.9442\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1575 - accuracy: 0.9483 - val_loss: 0.1697 - val_accuracy: 0.9442\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1606 - accuracy: 0.9458 - val_loss: 0.1691 - val_accuracy: 0.9442\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1439 - accuracy: 0.9562 - val_loss: 0.1688 - val_accuracy: 0.9442\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1467 - accuracy: 0.9510 - val_loss: 0.1682 - val_accuracy: 0.9442\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1578 - accuracy: 0.9484 - val_loss: 0.1676 - val_accuracy: 0.9442\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1516 - accuracy: 0.9484 - val_loss: 0.1670 - val_accuracy: 0.9464\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1508 - accuracy: 0.9458 - val_loss: 0.1664 - val_accuracy: 0.9464\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1379 - accuracy: 0.9562 - val_loss: 0.1663 - val_accuracy: 0.9464\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1393 - accuracy: 0.9590 - val_loss: 0.1659 - val_accuracy: 0.9464\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1453 - accuracy: 0.9566 - val_loss: 0.1655 - val_accuracy: 0.9464\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1461 - accuracy: 0.9566 - val_loss: 0.1651 - val_accuracy: 0.9464\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1629 - accuracy: 0.9408 - val_loss: 0.1647 - val_accuracy: 0.9464\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1441 - accuracy: 0.9512 - val_loss: 0.1643 - val_accuracy: 0.9464\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1418 - accuracy: 0.9486 - val_loss: 0.1641 - val_accuracy: 0.9487\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1475 - accuracy: 0.9512 - val_loss: 0.1641 - val_accuracy: 0.9487\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1416 - accuracy: 0.9540 - val_loss: 0.1638 - val_accuracy: 0.9487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efd80445a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwue0Q0Ksrwk",
        "outputId": "a954ebb3-f1fd-445c-a8f1-567c15dc08f5"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9324\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23386673629283905, 0.9324324131011963]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCA9r4YjCXQA",
        "outputId": "113aa9b0-6206-4fb7-c566-6e1c223532b7"
      },
      "source": [
        "model1.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19046083092689514, 0.9290540814399719]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31tpbIzkEXAL"
      },
      "source": [
        "a=model.predict(x_test)\n",
        "b=model1.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8FFmMPiEwbx"
      },
      "source": [
        "a=a[:10]\n",
        "b=b[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtZ2tQ_BE44I",
        "outputId": "ab5bd7a0-707d-49e3-9570-b95d85f9d3f0"
      },
      "source": [
        "a=np.asanyarray(a).reshape(10,)\n",
        "a.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwKibrDkE54u"
      },
      "source": [
        "labels=y_test[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH_-OPF1FFbC",
        "outputId": "37a406c0-10bd-476b-d8b5-6e9ea1990d5f"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 1, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXrfAlz_FGrN"
      },
      "source": [
        "f=pd.DataFrame({\"pedicted\":a,\"original\":labels})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Ey3Csh9mF5D1",
        "outputId": "6109c9e5-0287-458a-8454-44b2c498b417"
      },
      "source": [
        "f"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pedicted</th>\n",
              "      <th>original</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.107135</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.282742</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.991061</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.094848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.057057</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.944809</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.691829</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.160719</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.432702</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.083872</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pedicted  original\n",
              "0  0.107135         1\n",
              "1  0.282742         0\n",
              "2  0.991061         1\n",
              "3  0.094848         0\n",
              "4  0.057057         0\n",
              "5  0.944809         1\n",
              "6  0.691829         1\n",
              "7  0.160719         0\n",
              "8  0.432702         0\n",
              "9  0.083872         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGCz6aWLF5ul"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}